<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="动手深度学习(八):机器翻译简介, HopenX">
    <meta name="description" content="简要介绍机器翻译的基本任务与流程, Encoder-Decoder 模型, 集束搜索">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>动手深度学习(八):机器翻译简介 | HopenX</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/css/highlight/styles/github.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"></head>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    <div>
                        
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/logo.png" class="logo-img" alt="LOGO">
                        
                        <span class="logo-span">HopenX</span>
                    </div>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">HopenX</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/HopenX/hopenx.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #267871;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/HopenX/hopenx.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>



    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/featureimages/5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">动手深度学习(八):机器翻译简介</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #267871;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #267871;
    }

    #toc-content .is-active-link::before {
        background-color: #267871;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        
<style type="text/css">

    #articleContent a {
        color: #267871; !important;
    }

    #artDetail .post-cate a {
        color: #267871; !important;
    }

    blockquote {
        border-left: 5px solid #267871; !important;
    }

    #artDetail .reprint a {
        color: #267871; !important;
    }

    pre {
        background: #1d1d1d;
    }

    @font-face {
        font-family: 'Menlo';
        font-style: normal;
        font-weight: 400;
        src: url('https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/css/Menlo-Regular.ttf') format('ttf');
    }

    code{
        font-family: 'Menlo';
    }

</style>


<script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-NLP/">
                                <span class="chip bg-color">深度学习, NLP</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                机器学习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-02-20
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    4.1k
                </div>
                

                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="机器翻译和数据集"><a href="#机器翻译和数据集" class="headerlink" title="机器翻译和数据集"></a>机器翻译和数据集</h1><p>机器翻译（MT）：将一段文本从一种语言自动翻译为另一种语言，用神经网络解决这个问题通常称为神经机器翻译（NMT）。<br>主要特征：输出是单词<code>序列</code>而不是单个单词。 输出序列的长度可能与源序列的长度<code>不同</code>。</p>
<h2 id="机器翻译任务代码总结如下"><a href="#机器翻译任务代码总结如下" class="headerlink" title="机器翻译任务代码总结如下"></a>机器翻译任务代码总结如下</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ol>
<li><code>读取数据</code>，处理数据中的编码问题，并将无效的字符串删除</li>
<li><code>分词</code>，分词的目的就是将字符串转换成单词组成的列表。目前有很多现成的分词工具可以直接使用，也可以直接按照空格进行分词(不推荐，因为分词不是很准确)</li>
<li><code>建立词典</code>，将单词组成的列表编程单词id组成的列表，这里会得到如下几样东西<ol>
<li>去重后词典，及其中单词对应的索引列表</li>
<li>还可以得到给定索引找到其对应的单词的列表，以及给定单词得到对应索引的字典</li>
<li>原始语料所有词对应的词典索引的列表</li>
</ol>
</li>
<li>对数据进行<code>padding操作</code>。基于rnn的Seq2Seq模型，可以处理任意长度，“变长数据的读入”基于rnn的机器翻译也并不需要固定长度。要<code>padding</code>，是因为像tf、pytorch这些框架要求一个batch的数据必须长度相等，不然会报错；要<code>截断</code>，设置最大的数据长度是因为decode的时候达到这个长度我们就停止；再一个原因就是为了加快计算，不然的话为了单个特别长的数据，batch中的其他数据都补成这么长，很慢。</li>
<li><code>制作数据生成器</code>，但是需要注意的是对于翻译任务的数据格式，机器翻译的输入是一段文本序列，输出也是一段文本序列。</li>
</ol>
<h3 id="Seq2Seq模型的构建"><a href="#Seq2Seq模型的构建" class="headerlink" title="Seq2Seq模型的构建"></a>Seq2Seq模型的构建</h3><ol>
<li>先编码后解码的框架: 先对输入序列使用循环神经网络对他进行编码，编码成一个<code>向量</code>之后，再将编码得到的向量作为一个新的<code>解码循环神经网络</code>的隐藏状态的输入，进行解码，一次输出一个序列的元素，再将模型训练输出的序列元素与真实标签计算损失进行学习。</li>
<li>词嵌入: 一般情况下输入到编码网络中的数据不是一个<code>onehot</code>向量而是经过了编码之后的向量，比如由<code>word2vec</code>技术，让编码后的向量由更加丰富的含义。</li>
<li>在进行编码和解码的过程中数据都是以<code>时间步</code>展开，也就是(Seq_len,)这种形式的数据进行处理的</li>
<li>对于编码与解码的循环神经网络，可以通过控制隐藏层的<code>层数</code>及每一层隐藏层神经元的<code>数量</code>来控制模型的复杂度</li>
<li>编码部分，RNN的用0初始化隐含状态，最后的输出主要是隐藏状态, 编码RNN输出的隐含状态认为是其对应的编码向量</li>
<li>解码器的整体形状与编码器是一样的，只不过解码器的模型的隐藏状态是<code>由编码器的输出的隐藏状态初始化</code>的。</li>
</ol>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><ol>
<li>解码器的输出是一个和词典维度相同的向量，其每个值对应与向量索引位置对应词的分数，一般是选择<code>分数最大</code>的那个词作为最终的输出。</li>
<li>在计算损失函数之前，要把<code>padding去掉</code>，因为padding的部分不参与计算</li>
</ol>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><ol>
<li>解码器在测试的时候需要将模型的输出作为下一个时间步的输入</li>
<li>Beam Search搜索算法。<ol>
<li>假设预测的时候词典的大小为3，内容为a,b,c. <code>beam size</code>为2，解码的时候过程如下</li>
<li>生成第一个词的时候，选择概率最大的两个词，假设为a,c.那么当前的两个序列就是a和c。</li>
<li>生成第二个词的时候，将当前序列a和c，分别与此表中的所有词进行组合，得到新的6个序列aa ab ac ca cb cc,计算每个序列的得分，并选择得分最高的2个序列，作为新的当前序列，假如为aa cb </li>
<li>后面不断重复这个过程，直到遇到结束符或者达到最大长度为止，最终输出得分最高的2个序列。</li>
</ol>
</li>
</ol>
<pre><code class="lang-python">import os
os.listdir(&#39;/home/kesci/input/&#39;)
</code></pre>
<pre><code>[&#39;fraeng6506&#39;, &#39;d2l9528&#39;, &#39;d2l6239&#39;]
</code></pre><pre><code class="lang-python">import sys
sys.path.append(&#39;/home/kesci/input/d2l9528/&#39;)
import collections
import d2l
import zipfile
from d2l.data.base import Vocab
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils import data
from torch import optim
</code></pre>
<h3 id="数据预处理-1"><a href="#数据预处理-1" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>将数据集清洗、转化为神经网络的输入minbatch</p>
<pre><code class="lang-python">with open(&#39;/home/kesci/input/fraeng6506/fra.txt&#39;, &#39;r&#39;) as f:
      raw_text = f.read()
print(raw_text[0:1000])
</code></pre>
<pre><code>Go.    Va !    CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) &amp; #1158250 (Wittydev)
Hi.    Salut !    CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) &amp; #509819 (Aiji)
Hi.    Salut.    CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) &amp; #4320462 (gillux)
Run!    Cours !    CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) &amp; #906331 (sacredceltic)
Run!    Courez !    CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) &amp; #906332 (sacredceltic)
Who?    Qui ?    CC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) &amp; #4366796 (gillux)
Wow!    Ça alors !    CC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) &amp; #374631 (zmoo)
Fire!    Au feu !    CC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) &amp; #4627939 (sacredceltic)
Help!    À l&#39;aide !    CC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) &amp; #128430 (sysko)
Jump.    Saute.    CC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) &amp; #2416938 (Phoenix)
Stop!    Ça suffit !    CC-BY 2.0 (France) Attribution: tato
</code></pre><pre><code class="lang-python">def preprocess_raw(text):
    text = text.replace(&#39;\u202f&#39;, &#39; &#39;).replace(&#39;\xa0&#39;, &#39; &#39;)
    out = &#39;&#39;
    for i, char in enumerate(text.lower()):
        if char in (&#39;,&#39;, &#39;!&#39;, &#39;.&#39;) and i &gt; 0 and text[i-1] != &#39; &#39;:
            out += &#39; &#39;
        out += char
    return out

text = preprocess_raw(raw_text)
print(text[0:1000])
</code></pre>
<pre><code>go .    va !    cc-by 2 .0 (france) attribution: tatoeba .org #2877272 (cm) &amp; #1158250 (wittydev)
hi .    salut !    cc-by 2 .0 (france) attribution: tatoeba .org #538123 (cm) &amp; #509819 (aiji)
hi .    salut .    cc-by 2 .0 (france) attribution: tatoeba .org #538123 (cm) &amp; #4320462 (gillux)
run !    cours !    cc-by 2 .0 (france) attribution: tatoeba .org #906328 (papabear) &amp; #906331 (sacredceltic)
run !    courez !    cc-by 2 .0 (france) attribution: tatoeba .org #906328 (papabear) &amp; #906332 (sacredceltic)
who?    qui ?    cc-by 2 .0 (france) attribution: tatoeba .org #2083030 (ck) &amp; #4366796 (gillux)
wow !    ça alors !    cc-by 2 .0 (france) attribution: tatoeba .org #52027 (zifre) &amp; #374631 (zmoo)
fire !    au feu !    cc-by 2 .0 (france) attribution: tatoeba .org #1829639 (spamster) &amp; #4627939 (sacredceltic)
help !    à l&#39;aide !    cc-by 2 .0 (france) attribution: tatoeba .org #435084 (lukaszpp) &amp; #128430 (sysko)
jump .    saute .    cc-by 2 .0 (france) attribution: tatoeba .org #631038 (shishir) &amp; #2416938 (phoenix)
stop !    ça suffit !    cc-b
</code></pre><p>字符在计算机里是以编码的形式存在，我们通常所用的空格是 \x20 ，是在标准ASCII可见字符 0x20~0x7e 范围内。<br>而 \xa0 属于 latin1 （ISO/IEC_8859-1）中的扩展字符集字符，代表不间断空白符nbsp(non-breaking space)，超出gbk编码范围，是需要去除的特殊字符。再数据预处理的过程中，我们首先需要对数据进行清洗。</p>
<h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><p>字符串—-单词组成的列表</p>
<pre><code class="lang-python">num_examples = 50000
source, target = [], []
for i, line in enumerate(text.split(&#39;\n&#39;)):
    if i &gt; num_examples:
        break
    parts = line.split(&#39;\t&#39;)
    if len(parts) &gt;= 2:
        source.append(parts[0].split(&#39; &#39;))
        target.append(parts[1].split(&#39; &#39;))

source[0:3], target[0:3]
</code></pre>
<pre><code>([[&#39;go&#39;, &#39;.&#39;], [&#39;hi&#39;, &#39;.&#39;], [&#39;hi&#39;, &#39;.&#39;]],
 [[&#39;va&#39;, &#39;!&#39;], [&#39;salut&#39;, &#39;!&#39;], [&#39;salut&#39;, &#39;.&#39;]])
</code></pre><pre><code class="lang-python">d2l.set_figsize()
d2l.plt.hist([[len(l) for l in source], [len(l) for l in target]],label=[&#39;source&#39;, &#39;target&#39;])
d2l.plt.legend(loc=&#39;upper right&#39;);
</code></pre>
<p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/t19DZi4dB2XOPEn.png" alt="分词结果"></p>
<h3 id="建立词典"><a href="#建立词典" class="headerlink" title="建立词典"></a>建立词典</h3><p>单词组成的列表—-单词id组成的列表</p>
<pre><code class="lang-python">def build_vocab(tokens):
    tokens = [token for line in tokens for token in line]
    return d2l.data.base.Vocab(tokens, min_freq=3, use_special_tokens=True)

src_vocab = build_vocab(source)  # 4 个特殊字符，pad 补充 bos句开始 eos句结束 unk未知字符
len(src_vocab)
</code></pre>
<pre><code>3789
</code></pre><p><code>Vocab</code> 会进行词频统计, 从大到小排序<br><code>__len__</code> 返回长度<br><code>__getitem__</code> 返回单词对应的 id<br><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/3oBvEZdHYKXzwfg.png" alt="Vocab"></p>
<h3 id="载入数据集"><a href="#载入数据集" class="headerlink" title="载入数据集"></a>载入数据集</h3><p>进行 pad 保证句子长度是一样的, 一个 batch 使用的同一个长度</p>
<pre><code class="lang-python">def pad(line, max_len, padding_token):
    if len(line) &gt; max_len:
        return line[:max_len]
    return line + [padding_token] * (max_len - len(line))
pad(src_vocab[source[0]], 10, src_vocab.pad)
</code></pre>
<pre><code>[38, 4, 0, 0, 0, 0, 0, 0, 0, 0]
</code></pre><p>首尾标注 <code>bos</code> 和 <code>eos</code></p>
<pre><code class="lang-python">def build_array(lines, vocab, max_len, is_source):
    lines = [vocab[line] for line in lines]
    if not is_source:  # 如果是目标数据集，就要加一对首尾标注
        lines = [[vocab.bos] + line + [vocab.eos] for line in lines]
    array = torch.tensor([pad(line, max_len, vocab.pad) for line in lines])
    valid_len = (array != vocab.pad).sum(1) #第一个维度
    return array, valid_len
</code></pre>
<p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/LW4YMRvUpCA9ul6.png" alt="TensorDataset"></p>
<pre><code class="lang-python">def load_data_nmt(batch_size, max_len): # This function is saved in d2l.
    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)  # 先进行分词
    src_array, src_valid_len = build_array(source, src_vocab, max_len, True)  # 构建源语言数组
    tgt_array, tgt_valid_len = build_array(target, tgt_vocab, max_len, False) # 构建目标语言数组
    train_data = data.TensorDataset(src_array, src_valid_len, tgt_array, tgt_valid_len) 
    # TensorDataset 利用 assert 判断 4 个参数是不是一一对应的

    train_iter = data.DataLoader(train_data, batch_size, shuffle=True)
    return src_vocab, tgt_vocab, train_iter
</code></pre>
<p>X 是英语句子, Y 是法语句子</p>
<pre><code class="lang-python">src_vocab, tgt_vocab, train_iter = load_data_nmt(batch_size=2, max_len=8)
for X, X_valid_len, Y, Y_valid_len, in train_iter:
    print(&#39;X =&#39;, X.type(torch.int32), &#39;\nValid lengths for X =&#39;, X_valid_len,
        &#39;\nY =&#39;, Y.type(torch.int32), &#39;\nValid lengths for Y =&#39;, Y_valid_len)
    break
</code></pre>
<pre><code>X = tensor([[   5,   24,    3,    4,    0,    0,    0,    0],
        [  12, 1388,    7,    3,    4,    0,    0,    0]], dtype=torch.int32) 
Valid lengths for X = tensor([4, 5]) 
Y = tensor([[   1,   23,   46,    3,    3,    4,    2,    0],
        [   1,   15,  137,   27, 4736,    4,    2,    0]], dtype=torch.int32) 
Valid lengths for Y = tensor([7, 7])
</code></pre><h1 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h1><p> encoder：输入到隐藏状态<br> decoder：隐藏状态到输出</p>
<p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/7aEyZcGDVS1zXPU.png" alt="Encoder-Decoder"></p>
<pre><code class="lang-python">class Encoder(nn.Module):
    def __init__(self, **kwargs):
        super(Encoder, self).__init__(**kwargs)

    def forward(self, X, *args):
        raise NotImplementedError
</code></pre>
<pre><code class="lang-python">class Decoder(nn.Module):
    def __init__(self, **kwargs):
        super(Decoder, self).__init__(**kwargs)

    def init_state(self, enc_outputs, *args):
        raise NotImplementedError

    def forward(self, X, state):
        raise NotImplementedError
</code></pre>
<pre><code class="lang-python">class EncoderDecoder(nn.Module):
    def __init__(self, encoder, decoder, **kwargs):
        super(EncoderDecoder, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder

    def forward(self, enc_X, dec_X, *args):
        enc_outputs = self.encoder(enc_X, *args)
        dec_state = self.decoder.init_state(enc_outputs, *args)
        return self.decoder(dec_X, dec_state)
</code></pre>
<p>可以应用在对话系统、生成式任务中。</p>
<h1 id="Sequence-to-Sequence模型"><a href="#Sequence-to-Sequence模型" class="headerlink" title="Sequence to Sequence模型"></a>Sequence to Sequence模型</h1><h3 id="模型："><a href="#模型：" class="headerlink" title="模型："></a>模型：</h3><ul>
<li>训练（已知英语所对应的法语）</li>
<li>Encoder 是一个 RNN，可以是 LSTM 可以是 GRU</li>
<li>hidden state 就是 Encoder 得到的 ht，就是语义编码，也就是 Decoder 用来初始化的 $H_{-1}$</li>
<li>Decoder 就是一个生成语言模型，有了前几个生成后几个，类似于歌词生成<br><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/JL3VW7gznsGIStw.png" alt="生成"></li>
<li>预测（不知道对应的法语）</li>
</ul>
<p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/YhcpTl6nQERLosu.png" alt="预测"></p>
<h3 id="具体结构："><a href="#具体结构：" class="headerlink" title="具体结构："></a>具体结构：</h3><ul>
<li>比如 apple 对应的 id，会把它翻译成<code>词向量</code>，代表 apple 的含义</li>
<li><code>dense()</code>多用于CNN网络搭建时搭建全连接层使用，在RNN网络搭建，特别是涉及到用RNN做分类时，dense()可以用作RNN<code>分类预测输出</code>, 每个输出也是一个分类问题</li>
<li><code>embedding层</code>的作用就是给每个单词，赋一个特定的词向量<br><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/5otbRSFCVqhZDUK.png" alt="具体结构"><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3></li>
</ul>
<pre><code class="lang-python">class Seq2SeqEncoder(d2l.Encoder):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqEncoder, self).__init__(**kwargs)
        self.num_hiddens=num_hiddens
        self.num_layers=num_layers
        self.embedding = nn.Embedding(vocab_size, embed_size) # embed_size 词向量维度，输入单词的形状
        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)

    def begin_state(self, batch_size, device):  # 初始化
        return [torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device),
                torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device)]
    def forward(self, X, *args):
        X = self.embedding(X) # X shape: (batch_size, seq_len, embed_size) 
        # batch_size 有几句话，seq_len 一句话有几个单词，每个单词都变成了 embed_size 维的词向量
        X = X.transpose(0, 1)  # RNN 第一个维度应该是时间（句子的顺序是第一个维度），所以把第 1、2 维度调换一下
        # state = self.begin_state(X.shape[1], device=X.device)
        out, state = self.rnn(X) # out 是每个单元的输出，state 是最后一个单元的输出
        # out 的 shape 是 (seq_len, batch_size, num_hiddens).
        # state 包含最后一个记忆细胞的状态，和隐层状态
        # 在最后一步， state shape 是 (num_layers, batch_size, num_hiddens)
        return out, state
</code></pre>
<pre><code class="lang-python">encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8,num_hiddens=16, num_layers=2) #每个词用 8 维向量表示
X = torch.zeros((4, 7),dtype=torch.long)  # 输入 4 句话，每句话 7 个单词
output, state = encoder(X)
output.shape, len(state), state[0].shape, state[1].shape  # len(state)=2 表示包含了记忆细胞和隐层状态两个部分
</code></pre>
<pre><code>(torch.Size([7, 4, 16]), 2, torch.Size([2, 4, 16]), torch.Size([2, 4, 16]))
</code></pre><h1 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h1><pre><code class="lang-python">class Seq2SeqDecoder(d2l.Decoder):
    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqDecoder, self).__init__(**kwargs)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)
        self.dense = nn.Linear(num_hiddens,vocab_size) # dense 用于输出结果
        # 通过全连接层把16个隐藏单元映射到100个单词，在100 维度的向量里，选出评分最高的，作为结果输出

    def init_state(self, enc_outputs, *args):
        return enc_outputs[1]  # 用 Encoder 的输出作初始化

    def forward(self, X, state):
        X = self.embedding(X).transpose(0, 1)
        out, state = self.rnn(X, state)
        # Make the batch to be the first dimension to simplify loss computation.
        out = self.dense(out).transpose(0, 1)
        return out, state
</code></pre>
<pre><code class="lang-python">decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8,num_hiddens=16, num_layers=2)
state = decoder.init_state(encoder(X))
out, state = decoder(X, state)
out.shape, len(state), state[0].shape, state[1].shape  # out 4*7*10 10 代表单词表大小，在 10 个得分里选最高的
</code></pre>
<pre><code>(torch.Size([4, 7, 10]), 2, torch.Size([2, 4, 16]), torch.Size([2, 4, 16]))
</code></pre><h3 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h3><p>计算有效长度, 忽略 padding</p>
<pre><code class="lang-python">def SequenceMask(X, X_len,value=0):  
    # X 一个 batch 的输入，X_len 输入原本的有效长度（由于有 pad）
    maxlen = X.size(1)
    mask = torch.arange(maxlen)[None, :].to(X_len.device) &lt; X_len[:, None] # len 以后的部分都用 value 填充
    X[~mask]=value
    return X
</code></pre>
<pre><code class="lang-python">X = torch.tensor([[1,2,3], [4,5,6]])
SequenceMask(X,torch.tensor([1,2]))  # 第一句有效长度为 1，第二句有效长度为 2
</code></pre>
<pre><code>tensor([[1, 0, 0],
        [4, 5, 0]])
</code></pre><pre><code class="lang-python">X = torch.ones((2,3, 4))
SequenceMask(X, torch.tensor([1,2]),value=-1)
</code></pre>
<pre><code>tensor([[[ 1.,  1.,  1.,  1.],
         [-1., -1., -1., -1.],
         [-1., -1., -1., -1.]],

        [[ 1.,  1.,  1.,  1.],
         [ 1.,  1.,  1.,  1.],
         [-1., -1., -1., -1.]]])
</code></pre><p>定义交叉熵损失函数, 继承<code>CrossEntropyLoss</code></p>
<pre><code class="lang-python">class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):
    # pred shape: (batch_size, seq_len, vocab_size)
    # label shape: (batch_size, seq_len)
    # valid_length shape: (batch_size, )
    def forward(self, pred, label, valid_length):
        # the sample weights shape should be (batch_size, seq_len)
        weights = torch.ones_like(label)
        weights = SequenceMask(weights, valid_length).float()  # padding 部分的损失变成 0，保留有效长度部分的存世
        self.reduction=&#39;none&#39;
        output=super(MaskedSoftmaxCELoss, self).forward(pred.transpose(1,2), label)
        return (output*weights).mean(dim=1)
</code></pre>
<pre><code class="lang-python">loss = MaskedSoftmaxCELoss()
loss(torch.ones((3, 4, 10)), torch.ones((3,4),dtype=torch.long), torch.tensor([4,3,0])) 
# label 3个句子，4 个正确单词； 有效长度[4, 3, 0]
</code></pre>
<pre><code>tensor([2.3026, 1.7269, 0.0000])
</code></pre><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><pre><code class="lang-python">def train_ch7(model, data_iter, lr, num_epochs, device):  # Saved in d2l 如果device是GPU，下面的device都要设定
    model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    loss = MaskedSoftmaxCELoss()
    tic = time.time()
    for epoch in range(1, num_epochs+1):
        l_sum, num_tokens_sum = 0.0, 0.0  # loss 的总和，单词数量的总和
        for batch in data_iter:
            optimizer.zero_grad()
            X, X_vlen, Y, Y_vlen = [x.to(device) for x in batch]
            Y_input, Y_label, Y_vlen = Y[:,:-1], Y[:,1:], Y_vlen-1 # Y_input decoder的输入

            Y_hat, _ = model(X, Y_input, X_vlen, Y_vlen)
            l = loss(Y_hat, Y_label, Y_vlen).sum()
            l.backward()

            with torch.no_grad():
                d2l.grad_clipping_nn(model, 5, device)  #梯度裁剪
            num_tokens = Y_vlen.sum().item()
            optimizer.step()
            l_sum += l.sum().item()
            num_tokens_sum += num_tokens
        if epoch % 50 == 0:
            print(&quot;epoch {0:4d},loss {1:.3f}, time {2:.1f} sec&quot;.format( 
                  epoch, (l_sum/num_tokens_sum), time.time()-tic))
            tic = time.time()
</code></pre>
<pre><code class="lang-python">embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0
batch_size, num_examples, max_len = 64, 1e3, 10
lr, num_epochs, ctx = 0.005, 300, d2l.try_gpu()
src_vocab, tgt_vocab, train_iter = d2l.load_data_nmt(
    batch_size, max_len,num_examples)
encoder = Seq2SeqEncoder(
    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)
decoder = Seq2SeqDecoder(
    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)
model = d2l.EncoderDecoder(encoder, decoder)
train_ch7(model, train_iter, lr, num_epochs, ctx)
</code></pre>
<pre><code>epoch   50,loss 0.093, time 38.2 sec
epoch  100,loss 0.046, time 37.9 sec
epoch  150,loss 0.032, time 36.8 sec
epoch  200,loss 0.027, time 37.5 sec
epoch  250,loss 0.026, time 37.8 sec
epoch  300,loss 0.025, time 37.3 sec
</code></pre><h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><pre><code class="lang-python">def translate_ch7(model, src_sentence, src_vocab, tgt_vocab, max_len, device):
    src_tokens = src_vocab[src_sentence.lower().split(&#39; &#39;)]
    src_len = len(src_tokens)
    if src_len &lt; max_len:
        src_tokens += [src_vocab.pad] * (max_len - src_len)  # 进行 padding
    enc_X = torch.tensor(src_tokens, device=device)
    enc_valid_length = torch.tensor([src_len], device=device)
    # use expand_dim to add the batch_size dimension.
    enc_outputs = model.encoder(enc_X.unsqueeze(dim=0), enc_valid_length) # unsqueeze 增加一个维度（因为有多个 batch_size)
    dec_state = model.decoder.init_state(enc_outputs, enc_valid_length) # encoder 的输出作为 dec 的输入初始化
    dec_X = torch.tensor([tgt_vocab.bos], device=device).unsqueeze(dim=0) # 设为 bos 表示开始
    predict_tokens = []
    for _ in range(max_len):
        Y, dec_state = model.decoder(dec_X, dec_state) # 当前 RNN 单元的 output Y，给下一个单元的 dec_state
        dec_X = Y.argmax(dim=2)  # 得分最高的单词，作为下一个单元的输入
        py = dec_X.squeeze(dim=0).int().item()
        if py == tgt_vocab.eos:  # 结束则跳出循环
            break
        predict_tokens.append(py)
    return &#39; &#39;.join(tgt_vocab.to_tokens(predict_tokens))
</code></pre>
<pre><code class="lang-python">for sentence in [&#39;Go .&#39;, &#39;Wow !&#39;, &quot;I&#39;m OK .&quot;, &#39;I won !&#39;]:
    print(sentence + &#39; =&gt; &#39; + translate_ch7(
        model, sentence, src_vocab, tgt_vocab, max_len, ctx))
</code></pre>
<pre><code>Go . =&gt; va !
Wow ! =&gt; &lt;unk&gt; !
I&#39;m OK . =&gt; ça va .
I won ! =&gt; j&#39;ai gagné !
</code></pre><h2 id="Beam-Search-集束搜索"><a href="#Beam-Search-集束搜索" class="headerlink" title="Beam Search 集束搜索"></a>Beam Search 集束搜索</h2><p>简单greedy search：（贪心）只考虑了局部最优解</p>
<p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/emJlxcIbrCVTS1o.png" alt="简单贪心"></p>
<p>维特比算法：选择整体分数最高的句子（搜索空间太大）<br>集束搜索：每次不只选一个，选择 top n，增加备选项但又不全局搜索</p>
<p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/L5aI1irfAKm2znq.png" alt="集束搜索"></p>
<h2 id="练习题"><a href="#练习题" class="headerlink" title="练习题"></a>练习题</h2><p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/19/BAHTqRNlPsiMdyr.png" alt="机器翻译-练习题"></p>
<ul>
<li>训练时下一个单词是已知的, 预测时需要作为下一个单词生成的输入</li>
<li>每个 batch 之内, size 是给定的, 句子长度都是一样的</li>
</ul>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://hopenx.github.io" rel="external nofollow noreferrer">HopenX</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://hopenx.github.io/2020/02/20/dl-notes8-mach-trans/">https://hopenx.github.io/2020/02/20/dl-notes8-mach-trans/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://hopenx.github.io" target="_blank">HopenX</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-NLP/">
                                    <span class="chip bg-color">深度学习, NLP</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2020/02/20/dl-notes9-cnn-basic/">
                    <div class="card-image">
                        
                        
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/featureimages/23.jpg" class="responsive-img" alt="动手深度学习(九):卷积神经网络 CNN 基础">
                        
                        <span class="card-title">动手深度学习(九):卷积神经网络 CNN 基础</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            简要介绍 CNN 的基础概念, 卷积, 池化, 互相关运算, 特征图与感受野, 步幅与填充, 输入输出通道
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-02-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/02/19/dl-notes5-grad/">
                    <div class="card-image">
                        
                        
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/featureimages/5.jpg" class="responsive-img" alt="动手深度学习(五):梯度消失、梯度爆炸">
                        
                        <span class="card-title">动手深度学习(五):梯度消失、梯度爆炸</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            深度模型有关数值稳定性的典型问题是消失（vanishing）和爆炸（explosion）, 当神经网络的层数较多时，模型的数值稳定性容易变差
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-02-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>


    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://hopenx.github.io" target="_blank">HopenX</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">34.4k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "2";
                    var startHour = "0";
                    var startMinute = "";
                    var startSecond = "";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 ";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/hopenx" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>









    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1152214965" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1152214965" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/bo-xue-du-zhi-5" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/bo-xue-du-zhi-5" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>

<script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    
    
    
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/instantpage/instantpage.js" type="module"></script>
    

<script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>
