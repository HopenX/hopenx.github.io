<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="竞赛-房租预测, HopenX">
    <meta name="description" content="比赛要求参赛选手根据给定的数据集，建立模型，预测房屋租金, 数据集中的数据类别包括租赁房源、小区、二手房、配套、新房、土地、人口、客户、真实租金等">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>竞赛-房租预测 | HopenX</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/css/highlight/styles/github.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"></head>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    <div>
                        
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/logo.png" class="logo-img" alt="LOGO">
                        
                        <span class="logo-span">HopenX</span>
                    </div>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">HopenX</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/HopenX/hopenx.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #267871;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/HopenX/hopenx.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>



    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/featureimages/17.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">竞赛-房租预测</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #267871;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #267871;
    }

    #toc-content .is-active-link::before {
        background-color: #267871;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        
<style type="text/css">

    #articleContent a {
        color: #267871; !important;
    }

    #artDetail .post-cate a {
        color: #267871; !important;
    }

    blockquote {
        border-left: 5px solid #267871; !important;
    }

    #artDetail .reprint a {
        color: #267871; !important;
    }

    pre {
        background: #f8f8f8;
    }

    .code-area::after {
        content: " ";
        position: absolute;
        border-radius: 50%;
        /*background: #ff5f56;*/
        width: 12px;
        height: 12px;
        top: 0;
        left: 12px;
        margin-top: 12px;
        /*-webkit-box-shadow: 20px 0 #ffbd2e, 40px 0 #27c93f;*/
        /*box-shadow: 20px 0 #ffbd2e, 40px 0 #27c93f;*/
    }

    @font-face {
        font-family: 'Menlo';
        font-style: normal;
        font-weight: 400;
        src: url('https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/css/Menlo-Regular.ttf') format('ttf');
    }

    code{
        font-family: 'Menlo';
    }


</style>


<script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">机器学习</span>
                            </a>
                        
                            <a href="/tags/project/">
                                <span class="chip bg-color">project</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                机器学习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-02-26
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.2k
                </div>
                

                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="房租预测"><a href="#房租预测" class="headerlink" title="房租预测"></a>房租预测</h1><h2 id="一-赛题分析"><a href="#一-赛题分析" class="headerlink" title="(一) 赛题分析"></a>(一) 赛题分析</h2><p>比赛要求参赛选手根据给定的数据集，建立模型，预测房屋租金。<br>数据集中的数据类别包括租赁房源、小区、二手房、配套、新房、土地、人口、客户、真实租金等。<br>这是典型的<code>回归预测</code>。 </p>
<h3 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h3><p>探索性数据分析, Exploratory Data Analysis，简称EDA</p>
<p>传统：先假定数据服从某种分布，然后运用这种模型进行预测，以概率论为基础，做各种的参数检验。<br>EDA：“抛开”概率理论，从数据出发，强调数据可视化</p>
<p>参考资料：<br><a href="https://www.jianshu.com/p/9325c9f88ee6" target="_blank" rel="noopener">一文带你探索性数据分析(EDA)
</a></p>
<h2 id="1-预测指标"><a href="#1-预测指标" class="headerlink" title="1. 预测指标"></a>1. 预测指标</h2><h4 id="回归结果评价标准采用R-Square"><a href="#回归结果评价标准采用R-Square" class="headerlink" title="回归结果评价标准采用R-Square"></a>回归结果评价标准采用R-Square</h4><p><strong>R2（R-Square）的公式为</strong>：<br>残差平方和：(偏差)</p>
<script type="math/tex; mode=display">
SS_{res}=\sum\left(y_{i}-\hat{y}_{i}\right)^{2}</script><p>总平均值: (方差)</p>
<script type="math/tex; mode=display">
SS_{tot}=\sum\left(y_{i}-\overline{y}_{i}\right)^{2}</script><p>其中$\overline{y}$表示$y$的平均值<br>得到$R^2$表达式为：</p>
<script type="math/tex; mode=display">
R^{2}=1-\frac{SS_{res}}{SS_{tot}}=1-\frac{\sum\left(y_{i}-\hat{y}_{i}\right)^{2}}{\sum\left(y_{i}-\overline{y}\right)^{2}}</script><p>$R^2$用于度量<code>因变量的变异中,可由自变量解释部分所占的比例</code>，取值范围是 0~1，$R^2$越接近1,表明回归平方和占总平方和的比例越大,回归线与各观测点越接近，用x的变化来解释y值变化的部分就越多,回归的拟合程度就越好。所以$R^2$也称为<code>拟合优度</code>（Goodness of Fit）的统计量。</p>
<p>$y_{i}$表示真实值，$\hat{y}_{i}$表示预测值，$\overline{y}_{i}$表示样本均值。得分越高拟合效果越好。</p>
<h4 id="简要分析"><a href="#简要分析" class="headerlink" title="简要分析"></a>简要分析</h4><p>该份训练集包含 41440行×52列数据<br>目标变量是 真实房租价格- <strong>tradeMoney</strong> </p>
<p>大多数数据都是int或float型；有部分字段是object型，即文本型中文或英文的，如rentType字段，这些字段在之后需要做处理  </p>
<h2 id="4-分类特征和连续型特征"><a href="#4-分类特征和连续型特征" class="headerlink" title="4. 分类特征和连续型特征"></a>4. 分类特征和连续型特征</h2><pre><code class="lang-py"># 根据特征含义和特征一览，大致可以判断出数值型和类别型特征如下
categorical_feas = [&#39;rentType&#39;, &#39;houseType&#39;, &#39;houseFloor&#39;, &#39;region&#39;, &#39;plate&#39;, &#39;houseToward&#39;, &#39;houseDecoration&#39;,
    &#39;communityName&#39;,&#39;city&#39;,&#39;region&#39;,&#39;plate&#39;,&#39;buildYear&#39;]

numerical_feas=[&#39;ID&#39;,&#39;area&#39;,&#39;totalFloor&#39;,&#39;saleSecHouseNum&#39;,&#39;subwayStationNum&#39;,
    &#39;busStationNum&#39;,&#39;interSchoolNum&#39;,&#39;schoolNum&#39;,&#39;privateSchoolNum&#39;,&#39;hospitalNum&#39;,
    &#39;drugStoreNum&#39;,&#39;gymNum&#39;,&#39;bankNum&#39;,&#39;shopNum&#39;,&#39;parkNum&#39;,&#39;mallNum&#39;,&#39;superMarketNum&#39;,
    &#39;totalTradeMoney&#39;,&#39;totalTradeArea&#39;,&#39;tradeMeanPrice&#39;,&#39;tradeSecNum&#39;,&#39;totalNewTradeMoney&#39;,
    &#39;totalNewTradeArea&#39;,&#39;tradeNewMeanPrice&#39;,&#39;tradeNewNum&#39;,&#39;remainNewNum&#39;,&#39;supplyNewNum&#39;,
    &#39;supplyLandNum&#39;,&#39;supplyLandArea&#39;,&#39;tradeLandNum&#39;,&#39;tradeLandArea&#39;,&#39;landTotalPrice&#39;,
    &#39;landMeanPrice&#39;,&#39;totalWorkers&#39;,&#39;newWorkers&#39;,&#39;residentPopulation&#39;,&#39;pv&#39;,&#39;uv&#39;,&#39;lookNum&#39;]
</code></pre>
<h2 id="5-缺失值分析"><a href="#5-缺失值分析" class="headerlink" title="5. 缺失值分析"></a>5. 缺失值分析</h2><pre><code class="lang-py"># 缺失值分析
def missing_values(df):
    alldata_na = pd.DataFrame(df.isnull().sum(), columns={&#39;missingNum&#39;})
    alldata_na[&#39;existNum&#39;] = len(df) - alldata_na[&#39;missingNum&#39;]
    alldata_na[&#39;sum&#39;] = len(df)
    alldata_na[&#39;missingRatio&#39;] = alldata_na[&#39;missingNum&#39;]/len(df)*100
    alldata_na[&#39;dtype&#39;] = df.dtypes
    #ascending：默认True升序排列；False降序排列
    alldata_na = alldata_na[alldata_na[&#39;missingNum&#39;]&gt;0].reset_index().sort_values(by=[&#39;missingNum&#39;,&#39;index&#39;],ascending=[False,True])
    alldata_na.set_index(&#39;index&#39;,inplace=True)
    return alldata_na

missing_values(data_train)
</code></pre>
<p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/26/PtSeMBzNDTI8l3f.png" alt=""></p>
<h3 id="简要分析-1"><a href="#简要分析-1" class="headerlink" title="简要分析"></a>简要分析</h3><p>这里采用编写函数的方式来直接获取结果（这种方式会在之后反复用到，建议大家尽早养成函数式编写的习惯）；<br>其实在总体情况一览中，info()函数也能看出来。  </p>
<p>结果是，仅有pv、uv存在缺失值，后面再探究会发现缺失的都是属于同一个plate，可能是官方直接删除了该plate的pv、uv</p>
<h2 id="6-单调特征列分析"><a href="#6-单调特征列分析" class="headerlink" title="6. 单调特征列分析"></a>6. 单调特征列分析</h2><pre><code class="lang-py">#是否有单调特征列(单调的特征列很大可能是时间)
def incresing(vals):
    cnt = 0
    len_ = len(vals)
    for i in range(len_-1):
        if vals[i+1] &gt; vals[i]:
            cnt += 1
    return cnt

fea_cols = [col for col in data_train.columns]
for col in fea_cols:
    cnt = incresing(data_train[col].values)
    if cnt / data_train.shape[0] &gt;= 0.55:
        print(&#39;单调特征：&#39;,col)
        print(&#39;单调特征值个数：&#39;, cnt)
        print(&#39;单调特征值比例：&#39;, cnt / data_train.shape[0])
</code></pre>
<p>单调特征： tradeTime<br>单调特征值个数： 24085<br>单调特征值比例： 0.5812017374517374</p>
<h3 id="简要分析-2"><a href="#简要分析-2" class="headerlink" title="简要分析"></a>简要分析</h3><p>先编写判断单调的函数 <em>incresing</em>， 然后再应用到每列上；<br>单调特征是 tradeTime，为时间列。  </p>
<p>多说句额外的，时间列在特征工程的时候，不同的情况下能有很多的变种形式，比如按年月日分箱，或者按不同的维度在时间上聚合分组，等等  </p>
<h2 id="7-特征nunique分布"><a href="#7-特征nunique分布" class="headerlink" title="7. 特征nunique分布"></a>7. 特征nunique分布</h2><pre><code class="lang-py"># 特征nunique分布
# unique()是以 数组形式（numpy.ndarray）返回列的所有唯一值（特征的所有唯一值）nunique 返回唯一值的个数
for feature in categorical_feas:   # 类别型特征
    print(feature + &quot;的特征分布如下：&quot;)
    print(data_train[feature].value_counts())
    if feature != &#39;communityName&#39;: # communityName值太多，暂且不看图表
        plt.hist(data_all[feature], bins=3)
        plt.show()
</code></pre>
<h3 id="简要分析-3"><a href="#简要分析-3" class="headerlink" title="简要分析"></a>简要分析</h3><p>用自带函数value_counts() 来得到每个分类变量的 种类 分布；<br>并且简单画出柱状图。  </p>
<p>rentType：4种，且绝大多数是无用的未知方式；<br>houseType：104种，绝大多数在3室及以下；<br>houseFloor：3种，分布较为均匀；<br>region：       15种；<br>plate：        66种；<br>houseToward：    10种；<br>houseDecoration： 4种，一大半是其他；<br>buildYear：     80种；<br>communityName：   4236种，且分布较为稀疏；  </p>
<p>此步骤是为之后数据处理和特征工程做准备，先理解每个字段的含义以及分布，之后需要根据实际含义对分类变量做不同的处理。</p>
<h2 id="8-统计特征值频次大于100的特征"><a href="#8-统计特征值频次大于100的特征" class="headerlink" title="8. 统计特征值频次大于100的特征"></a>8. 统计特征值频次大于100的特征</h2><pre><code class="lang-py"># 统计特征值出现频次大于100的特征
for feature in categorical_feas:
    df_value_counts = pd.DataFrame(data_train[feature].value_counts())
    df_value_counts = df_value_counts.reset_index()
    df_value_counts.columns = [feature, &#39;counts&#39;] # 列的名字
    print(df_value_counts[df_value_counts[&#39;counts&#39;] &gt;= 100])
</code></pre>
<pre><code>  rentType  counts
0     未知方式   30759
1       整租    5472
2       合租    5204
   houseType  counts
0     1室1厅1卫    9805
1     2室1厅1卫    8512
2     2室2厅1卫    6783
3     3室1厅1卫    3992
4     3室2厅2卫    2737
5     4室1厅1卫    1957
6     3室2厅1卫    1920
7     1室0厅1卫    1286
8     1室2厅1卫     933
9     2室2厅2卫     881
10    4室2厅2卫     435
11    2室0厅1卫     419
......
</code></pre><h3 id="简要分析-4"><a href="#简要分析-4" class="headerlink" title="简要分析"></a>简要分析</h3><p>此步骤和特征nunique分布结合步骤结合起来看，有一些小于100的是可以直接统一归类为其他的</p>
<h2 id="9-Label分布"><a href="#9-Label分布" class="headerlink" title="9. Label分布"></a>9. Label分布</h2><p>分段进行 tradeMoney 的绘图 (tradeMoney 就是最后要预测的值)</p>
<pre><code class="lang-py"># Label 分布
fig,axes = plt.subplots(2,3,figsize=(20,5))
fig.set_size_inches(20,12)
sns.distplot(data_train[&#39;tradeMoney&#39;],ax=axes[0][0])
sns.distplot(data_train[(data_train[&#39;tradeMoney&#39;]&lt;=20000)][&#39;tradeMoney&#39;],ax=axes[0][1])
sns.distplot(data_train[(data_train[&#39;tradeMoney&#39;]&gt;20000)&amp;(data_train[&#39;tradeMoney&#39;]&lt;=50000)][&#39;tradeMoney&#39;],ax=axes[0][2])
sns.distplot(data_train[(data_train[&#39;tradeMoney&#39;]&gt;50000)&amp;(data_train[&#39;tradeMoney&#39;]&lt;=100000)][&#39;tradeMoney&#39;],ax=axes[1][0])
sns.distplot(data_train[(data_train[&#39;tradeMoney&#39;]&gt;100000)][&#39;tradeMoney&#39;],ax=axes[1][1])
</code></pre>
<p>money&lt;=10000 38964<br>10000&lt;money&lt;=20000 1985<br>20000&lt;money&lt;=50000 433<br>50000&lt;money&lt;=100000 39<br>100000&lt;money 19</p>
<h3 id="简要分析-5"><a href="#简要分析-5" class="headerlink" title="简要分析"></a>简要分析</h3><p>将目标变量tradeMoney分组，并查看每组间的分布；<br>可以看出绝大多数都是集中在10000元以内的，并且从图中可以看到该分布是右偏的。  </p>
<p>这里只是一种实现方式，完全可以将tradeMoney和其他字段一起结合起来查看，比如楼层高低，地区板块。  </p>
<h2 id="二-数据清洗"><a href="#二-数据清洗" class="headerlink" title="(二) 数据清洗"></a>(二) 数据清洗</h2><h3 id="缺失值分析及处理"><a href="#缺失值分析及处理" class="headerlink" title="缺失值分析及处理"></a>缺失值分析及处理</h3><ul>
<li>缺失值出现的原因分析</li>
<li>采取合适的方式对缺失值进行填充</li>
</ul>
<h3 id="异常值分析及处理"><a href="#异常值分析及处理" class="headerlink" title="异常值分析及处理"></a>异常值分析及处理</h3><ul>
<li><p>根据测试集数据的分布处理训练集的数据分布</p>
</li>
<li><p>使用合适的方法找出异常值</p>
</li>
<li>对异常值进行处理</li>
</ul>
<h3 id="深度清洗"><a href="#深度清洗" class="headerlink" title="深度清洗"></a>深度清洗</h3><ul>
<li>分析每一个communityName、city、region、plate的数据分布并对其进行数据清洗</li>
</ul>
<h2 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h2><p>虽然这步骤是缺失值处理，但还会涉及到一些最最基础的数据处理。  </p>
<ol>
<li><p><strong>主要思路分析</strong><br>缺失值的处理手段大体可以分为：<code>删除、填充、映射到高维(当做类别处理)</code>.<br>根据任务一，直接找到的缺失值情况是pu和pv；但是，根据特征nunique分布的分析，可以发现rentType存在”—“的情况，这也算是一种缺失值.<br>此外，诸如rentType的”未知方式”；houseToward的”暂无数据”等，本质上也算是一种缺失值，但是对于这些缺失方式，我们可以把它当做是<code>特殊的一类</code>处理，而不需要去主动修改或填充值. </p>
<p> (1) 将rentType的”—“转换成<code>未知方式</code>类别；<br> (2) pv/pu的缺失值用<code>均值</code>填充；<br> (3) buildYear存在”暂无信息”，将其用<code>众数</code>填充。  </p>
</li>
</ol>
<ol>
<li><strong>转换object类型数据</strong><br>这里直接采用<code>LabelEncoder</code>的方式编码，详细的编码方式见相关资料.  </li>
</ol>
<ol>
<li><strong>时间字段的处理</strong><br>buildYear由于存在”暂无信息”,所以需要主动将其转换int类型；<br>tradeTime，将其分割成月和日.</li>
</ol>
<ol>
<li><strong>删除无关字段</strong><br>ID是唯一码，建模无用，所以直接删除；<br>city只有一个SH值，也直接删除；<br>tradeTime已经分割成月和日，删除原来字段</li>
</ol>
<h2 id="异常值处理"><a href="#异常值处理" class="headerlink" title="异常值处理"></a>异常值处理</h2><p>这里主要针对area和tradeMoney两个维度处理。<br>针对tradeMoney，这里采用的是IsolationForest模型自动处理；<br>针对area和totalFloor是主观+数据可视化的方式得到的结果。</p>
<p>参考资料：<br><a href="https://zhuanlan.zhihu.com/p/25040651" target="_blank" rel="noopener">iForest （Isolation Forest）孤立森林 异常检测 入门篇</a></p>
<pre><code class="lang-py"># clean data
def IF_drop(train):
    IForest = IsolationForest(contamination=0.01)
    IForest.fit(train[&quot;tradeMoney&quot;].values.reshape(-1,1))
    y_pred = IForest.predict(train[&quot;tradeMoney&quot;].values.reshape(-1,1))
    drop_index = train.loc[y_pred==-1].index
    print(drop_index)
    train.drop(drop_index,inplace=True)
    return train

data_train = IF_drop(data_train)

def dropData(train):
    # 丢弃部分异常值
    train = train[train.area &lt;= 200]
    train = train[(train.tradeMoney &lt;=16000) &amp; (train.tradeMoney &gt;=700)]
    train.drop(train[(train[&#39;totalFloor&#39;] == 0)].index, inplace=True)
    return train  
#数据集异常值处理
data_train = dropData(data_train)
</code></pre>
<pre><code class="lang-py"># 处理异常值后再次查看面积和租金分布图
plt.figure(figsize=(15,5))
sns.boxplot(data_train.area)
plt.show()
plt.figure(figsize=(15,5))
sns.boxplot(data_train.tradeMoney),
plt.show()
</code></pre>
<p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/26/FSBwQgIRaWX1OLv.png" alt="tradeMoney"></p>
<p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/26/l5v69PJUBwndINO.png" alt="area"></p>
<h2 id="深度清洗-1"><a href="#深度清洗-1" class="headerlink" title="深度清洗"></a>深度清洗</h2><p>针对每一个region的数据，对area和tradeMoney两个维度进行深度清洗, 逐个逐个 drop.<br>采用主观+数据可视化的方式.</p>
<pre><code class="lang-py">def cleanData(data):
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00001&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;1000)&amp;(data[&#39;area&#39;]&gt;50)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00001&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;25000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00001&#39;) &amp; (data[&#39;area&#39;]&gt;250)&amp;(data[&#39;tradeMoney&#39;]&lt;20000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00001&#39;) &amp; (data[&#39;area&#39;]&gt;400)&amp;(data[&#39;tradeMoney&#39;]&gt;50000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00001&#39;) &amp; (data[&#39;area&#39;]&gt;100)&amp;(data[&#39;tradeMoney&#39;]&lt;2000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00002&#39;) &amp; (data[&#39;area&#39;]&lt;100)&amp;(data[&#39;tradeMoney&#39;]&gt;60000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00003&#39;) &amp; (data[&#39;area&#39;]&lt;300)&amp;(data[&#39;tradeMoney&#39;]&gt;30000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00003&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;500)&amp;(data[&#39;area&#39;]&lt;50)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00003&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;1500)&amp;(data[&#39;area&#39;]&gt;100)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00003&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;2000)&amp;(data[&#39;area&#39;]&gt;300)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00003&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;5000)&amp;(data[&#39;area&#39;]&lt;20)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00003&#39;) &amp; (data[&#39;area&#39;]&gt;600)&amp;(data[&#39;tradeMoney&#39;]&gt;40000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00004&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;1000)&amp;(data[&#39;area&#39;]&gt;80)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00006&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;200)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00005&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;2000)&amp;(data[&#39;area&#39;]&gt;180)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00005&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;50000)&amp;(data[&#39;area&#39;]&lt;200)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00006&#39;) &amp; (data[&#39;area&#39;]&gt;200)&amp;(data[&#39;tradeMoney&#39;]&lt;2000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00007&#39;) &amp; (data[&#39;area&#39;]&gt;100)&amp;(data[&#39;tradeMoney&#39;]&lt;2500)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00010&#39;) &amp; (data[&#39;area&#39;]&gt;200)&amp;(data[&#39;tradeMoney&#39;]&gt;25000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00010&#39;) &amp; (data[&#39;area&#39;]&gt;400)&amp;(data[&#39;tradeMoney&#39;]&lt;15000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00010&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;3000)&amp;(data[&#39;area&#39;]&gt;200)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00010&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;7000)&amp;(data[&#39;area&#39;]&lt;75)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00010&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;12500)&amp;(data[&#39;area&#39;]&lt;100)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00004&#39;) &amp; (data[&#39;area&#39;]&gt;400)&amp;(data[&#39;tradeMoney&#39;]&gt;20000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00008&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;2000)&amp;(data[&#39;area&#39;]&gt;80)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00009&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;40000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00009&#39;) &amp; (data[&#39;area&#39;]&gt;300)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00009&#39;) &amp; (data[&#39;area&#39;]&gt;100)&amp;(data[&#39;tradeMoney&#39;]&lt;2000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00011&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;10000)&amp;(data[&#39;area&#39;]&gt;390)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00012&#39;) &amp; (data[&#39;area&#39;]&gt;120)&amp;(data[&#39;tradeMoney&#39;]&lt;5000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00013&#39;) &amp; (data[&#39;area&#39;]&lt;100)&amp;(data[&#39;tradeMoney&#39;]&gt;40000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00013&#39;) &amp; (data[&#39;area&#39;]&gt;400)&amp;(data[&#39;tradeMoney&#39;]&gt;50000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00013&#39;) &amp; (data[&#39;area&#39;]&gt;80)&amp;(data[&#39;tradeMoney&#39;]&lt;2000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00014&#39;) &amp; (data[&#39;area&#39;]&gt;300)&amp;(data[&#39;tradeMoney&#39;]&gt;40000)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00014&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;1300)&amp;(data[&#39;area&#39;]&gt;80)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00014&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;8000)&amp;(data[&#39;area&#39;]&gt;200)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00014&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;1000)&amp;(data[&#39;area&#39;]&gt;20)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00014&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;25000)&amp;(data[&#39;area&#39;]&gt;200)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00014&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;20000)&amp;(data[&#39;area&#39;]&gt;250)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00005&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;30000)&amp;(data[&#39;area&#39;]&lt;100)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00005&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;50000)&amp;(data[&#39;area&#39;]&gt;600)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00005&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;50000)&amp;(data[&#39;area&#39;]&gt;350)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00006&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;4000)&amp;(data[&#39;area&#39;]&lt;100)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00006&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;600)&amp;(data[&#39;area&#39;]&gt;100)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00006&#39;) &amp; (data[&#39;area&#39;]&gt;165)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00012&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;800)&amp;(data[&#39;area&#39;]&lt;30)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00007&#39;) &amp; (data[&#39;tradeMoney&#39;]&lt;1100)&amp;(data[&#39;area&#39;]&gt;50)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00004&#39;) &amp; (data[&#39;tradeMoney&#39;]&gt;8000)&amp;(data[&#39;area&#39;]&lt;80)].index,inplace=True)
    data.loc[(data[&#39;region&#39;]==&#39;RG00002&#39;)&amp;(data[&#39;area&#39;]&gt;50)&amp;(data[&#39;rentType&#39;]==&#39;合租&#39;),&#39;rentType&#39;]=&#39;整租&#39;
    data.loc[(data[&#39;region&#39;]==&#39;RG00014&#39;)&amp;(data[&#39;rentType&#39;]==&#39;合租&#39;)&amp;(data[&#39;area&#39;]&gt;60),&#39;rentType&#39;]=&#39;整租&#39;
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00008&#39;)&amp;(data[&#39;tradeMoney&#39;]&gt;15000)&amp;(data[&#39;area&#39;]&lt;110)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00008&#39;)&amp;(data[&#39;tradeMoney&#39;]&gt;20000)&amp;(data[&#39;area&#39;]&gt;110)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00008&#39;)&amp;(data[&#39;tradeMoney&#39;]&lt;1500)&amp;(data[&#39;area&#39;]&lt;50)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00008&#39;)&amp;(data[&#39;rentType&#39;]==&#39;合租&#39;)&amp;(data[&#39;area&#39;]&gt;50)].index,inplace=True)
    data.drop(data[(data[&#39;region&#39;]==&#39;RG00015&#39;) ].index,inplace=True)
    data.reset_index(drop=True, inplace=True)
    return data

data_train = cleanData(data_train)
</code></pre>
<h2 id="三-特征工程"><a href="#三-特征工程" class="headerlink" title="(三) 特征工程"></a>(三) 特征工程</h2><pre><code class="lang-python">#核心代码举例

# 统计特征
    #计算均值
    gp = train.groupby(by)[fea].mean()
    #计算中位数
    gp = train.groupby(by)[fea].median()
    #计算方差
    gp = train.groupby(by)[fea].std()
    #计算最大值
    gp = train.groupby(by)[fea].max()
    #计算最小值
    gp = train.groupby(by)[fea].min()
    #计算出现次数
    gp = train.groupby(by)[fea].size()


# groupby生成统计特征：mean,std
    # 按照communityName分组计算面积的均值和方差
    temp = data.groupby(&#39;communityName&#39;)[&#39;area&#39;].agg({&#39;com_area_mean&#39;: &#39;mean&#39;, &#39;com_area_std&#39;: &#39;std&#39;})

# 特征拆分
    # 将houseType转为&#39;Room&#39;，&#39;Hall&#39;，&#39;Bath&#39;
    def Room(x):
        Room = int(x.split(&#39;室&#39;)[0])
        return Room
    def Hall(x):
        Hall = int(x.split(&quot;室&quot;)[1].split(&quot;厅&quot;)[0])
        return Hall
    def Bath(x):
        Bath = int(x.split(&quot;室&quot;)[1].split(&quot;厅&quot;)[1].split(&quot;卫&quot;)[0])
        return Bath

    data[&#39;Room&#39;] = data[&#39;houseType&#39;].apply(lambda x: Room(x))
    data[&#39;Hall&#39;] = data[&#39;houseType&#39;].apply(lambda x: Hall(x))
    data[&#39;Bath&#39;] = data[&#39;houseType&#39;].apply(lambda x: Bath(x))

#特征合并
    # 合并部分配套设施特征
    data[&#39;trainsportNum&#39;] = 5 * data[&#39;subwayStationNum&#39;] / data[&#39;subwayStationNum&#39;].mean() + data[&#39;busStationNum&#39;] / \
                                                                                             data[
                                                                                                 &#39;busStationNum&#39;].mean()

# 交叉生成特征:特征之间交叉+ - * / 
data[&#39;Room_Bath&#39;] = (data[&#39;Bath&#39;]+1) / (data[&#39;Room&#39;]+1)


# 聚类特征
from sklearn.mixture import GaussianMixture  使用GaussianMixture做聚类特征
gmm = GaussianMixture(n_components=4, covariance_type=&#39;full&#39;, random_state=0)
gmm.fit_predict(data)

# 特征编码
from sklearn.preprocessing import LabelEncoder
data[&#39;communityName&#39;] = LabelEncoder().fit_transform(data[&#39;communityName&#39;])
from sklearn import preprocessing.OneHotEncoder
data[&#39;communityName&#39;] = OneHotEncoder().fit_transform(data[&#39;communityName&#39;])


# 过大量级值取log平滑（针对线性模型有效）
data[feature]=np.log1p(data[feature])
</code></pre>
<pre><code class="lang-python">import pandas as pd
import warnings
warnings.filterwarnings(&#39;ignore&#39;)
from sklearn.preprocessing import LabelEncoder

train = pd.read_csv(&#39;./train_data.csv&#39;)
test = pd.read_csv(&#39;./test_a.csv&#39;)
target_train = train.pop(&#39;tradeMoney&#39;)
target_test = test.pop(&#39;tradeMoney&#39;)
</code></pre>
<h3 id="特征合并"><a href="#特征合并" class="headerlink" title="特征合并"></a>特征合并</h3><pre><code class="lang-python">def newfeature(data):


    # 将houseType转为&#39;Room&#39;，&#39;Hall&#39;，&#39;Bath&#39;
    def Room(x):
        Room = int(x.split(&#39;室&#39;)[0])
        return Room
    def Hall(x):
        Hall = int(x.split(&quot;室&quot;)[1].split(&quot;厅&quot;)[0])
        return Hall
    def Bath(x):
        Bath = int(x.split(&quot;室&quot;)[1].split(&quot;厅&quot;)[1].split(&quot;卫&quot;)[0])
        return Bath

    data[&#39;Room&#39;] = data[&#39;houseType&#39;].apply(lambda x: Room(x))
    data[&#39;Hall&#39;] = data[&#39;houseType&#39;].apply(lambda x: Hall(x))
    data[&#39;Bath&#39;] = data[&#39;houseType&#39;].apply(lambda x: Bath(x))
    data[&#39;Room_Bath&#39;] = (data[&#39;Bath&#39;]+1) / (data[&#39;Room&#39;]+1)
    # 填充租房类型  loc 取行数据
    data.loc[(data[&#39;rentType&#39;] == &#39;未知方式&#39;) &amp; (data[&#39;Room&#39;] &lt;= 1), &#39;rentType&#39;] = &#39;整租&#39;
    # print(data.loc[(data[&#39;rentType&#39;]==&#39;未知方式&#39;)&amp;(data[&#39;Room_Bath&#39;]&gt;1),&#39;rentType&#39;])
    data.loc[(data[&#39;rentType&#39;] == &#39;未知方式&#39;) &amp; (data[&#39;Room_Bath&#39;] &gt; 1), &#39;rentType&#39;] = &#39;合租&#39;
    data.loc[(data[&#39;rentType&#39;] == &#39;未知方式&#39;) &amp; (data[&#39;Room&#39;] &gt; 1) &amp; (data[&#39;area&#39;] &lt; 50), &#39;rentType&#39;] = &#39;合租&#39;
    data.loc[(data[&#39;rentType&#39;] == &#39;未知方式&#39;) &amp; (data[&#39;area&#39;] / data[&#39;Room&#39;] &lt; 20), &#39;rentType&#39;] = &#39;合租&#39;
    # data.loc[(data[&#39;rentType&#39;]==&#39;未知方式&#39;)&amp;(data[&#39;area&#39;]&gt;60),&#39;rentType&#39;]=&#39;合租&#39;
    data.loc[(data[&#39;rentType&#39;] == &#39;未知方式&#39;) &amp; (data[&#39;area&#39;] &lt;= 50) &amp; (data[&#39;Room&#39;] == 2), &#39;rentType&#39;] = &#39;合租&#39;
    data.loc[(data[&#39;rentType&#39;] == &#39;未知方式&#39;) &amp; (data[&#39;area&#39;] &gt; 60) &amp; (data[&#39;Room&#39;] == 2), &#39;rentType&#39;] = &#39;整租&#39;
    data.loc[(data[&#39;rentType&#39;] == &#39;未知方式&#39;) &amp; (data[&#39;area&#39;] &lt;= 60) &amp; (data[&#39;Room&#39;] == 3), &#39;rentType&#39;] = &#39;合租&#39;
    data.loc[(data[&#39;rentType&#39;] == &#39;未知方式&#39;) &amp; (data[&#39;area&#39;] &gt; 60) &amp; (data[&#39;Room&#39;] == 3), &#39;rentType&#39;] = &#39;整租&#39;
    data.loc[(data[&#39;rentType&#39;] == &#39;未知方式&#39;) &amp; (data[&#39;area&#39;] &gt;= 100) &amp; (data[&#39;Room&#39;] &gt; 3), &#39;rentType&#39;] = &#39;整租&#39;

    # data.drop(&#39;Room_Bath&#39;, axis=1, inplace=True)
    # 提升0.0001
    def month(x):
        month = int(x.split(&#39;/&#39;)[1])
        return month
    # def day(x):
    #     day = int(x.split(&#39;/&#39;)[2])
    #     return day
    # 结果变差

    # 分割交易时间
    # data[&#39;year&#39;]=data[&#39;tradeTime&#39;].apply(lambda x:year(x))
    data[&#39;month&#39;] = data[&#39;tradeTime&#39;].apply(lambda x: month(x))
    # data[&#39;day&#39;] = data[&#39;tradeTime&#39;].apply(lambda x: day(x))# 结果变差
    #     data[&#39;pv/uv&#39;] = data[&#39;pv&#39;] / data[&#39;uv&#39;]
    #     data[&#39;房间总数&#39;] = data[&#39;室&#39;] + data[&#39;厅&#39;] + data[&#39;卫&#39;]

    # 合并部分配套设施特征
    data[&#39;trainsportNum&#39;] = 5 * data[&#39;subwayStationNum&#39;] / data[&#39;subwayStationNum&#39;].mean() + data[&#39;busStationNum&#39;] / \
                                                                                             data[
                                                                                                 &#39;busStationNum&#39;].mean()
    data[&#39;all_SchoolNum&#39;] = 2 * data[&#39;interSchoolNum&#39;] / data[&#39;interSchoolNum&#39;].mean() + data[&#39;schoolNum&#39;] / data[
        &#39;schoolNum&#39;].mean() \
                            + data[&#39;privateSchoolNum&#39;] / data[&#39;privateSchoolNum&#39;].mean()
    data[&#39;all_hospitalNum&#39;] = 2 * data[&#39;hospitalNum&#39;] / data[&#39;hospitalNum&#39;].mean() + \
                              data[&#39;drugStoreNum&#39;] / data[&#39;drugStoreNum&#39;].mean()
    data[&#39;all_mall&#39;] = data[&#39;mallNum&#39;] / data[&#39;mallNum&#39;].mean() + \
                       data[&#39;superMarketNum&#39;] / data[&#39;superMarketNum&#39;].mean()
    data[&#39;otherNum&#39;] = data[&#39;gymNum&#39;] / data[&#39;gymNum&#39;].mean() + data[&#39;bankNum&#39;] / data[&#39;bankNum&#39;].mean() + \
                       data[&#39;shopNum&#39;] / data[&#39;shopNum&#39;].mean() + 2 * data[&#39;parkNum&#39;] / data[&#39;parkNum&#39;].mean()

    data.drop([&#39;subwayStationNum&#39;, &#39;busStationNum&#39;,
               &#39;interSchoolNum&#39;, &#39;schoolNum&#39;, &#39;privateSchoolNum&#39;,
               &#39;hospitalNum&#39;, &#39;drugStoreNum&#39;, &#39;mallNum&#39;, &#39;superMarketNum&#39;, &#39;gymNum&#39;, &#39;bankNum&#39;, &#39;shopNum&#39;, &#39;parkNum&#39;],
              axis=1, inplace=True)
    # 提升0.0005

#     data[&#39;houseType_1sumcsu&#39;]=data[&#39;Bath&#39;].map(lambda x:str(x))+data[&#39;month&#39;].map(lambda x:str(x))
#     data[&#39;houseType_2sumcsu&#39;]=data[&#39;Bath&#39;].map(lambda x:str(x))+data[&#39;communityName&#39;]
#     data[&#39;houseType_3sumcsu&#39;]=data[&#39;Bath&#39;].map(lambda x:str(x))+data[&#39;plate&#39;]

    data.drop(&#39;houseType&#39;, axis=1, inplace=True)
    data.drop(&#39;tradeTime&#39;, axis=1, inplace=True)

    data[&quot;area&quot;] = data[&quot;area&quot;].astype(int)


    # categorical_feats = [&#39;rentType&#39;, &#39;houseFloor&#39;, &#39;houseToward&#39;, &#39;houseDecoration&#39;, &#39;communityName&#39;,&#39;region&#39;, &#39;plate&#39;]
    categorical_feats = [&#39;rentType&#39;, &#39;houseFloor&#39;, &#39;houseToward&#39;, &#39;houseDecoration&#39;,  &#39;region&#39;, &#39;plate&#39;,&#39;cluster&#39;]

    return data, categorical_feats
</code></pre>
<h3 id="计算统计特征"><a href="#计算统计特征" class="headerlink" title="计算统计特征"></a>计算统计特征</h3><pre><code class="lang-python">#计算统计特征
def featureCount(train,test):
    train[&#39;data_type&#39;] = 0
    test[&#39;data_type&#39;] = 1
    data = pd.concat([train, test], axis=0, join=&#39;outer&#39;)
    def feature_count(data, features=[]):
        new_feature = &#39;count&#39;
        for i in features:
            new_feature += &#39;_&#39; + i
        temp = data.groupby(features).size().reset_index().rename(columns={0: new_feature})
        data = data.merge(temp, &#39;left&#39;, on=features)
        return data

    data = feature_count(data, [&#39;communityName&#39;])
    data = feature_count(data, [&#39;buildYear&#39;])
    data = feature_count(data, [&#39;totalFloor&#39;])
    data = feature_count(data, [&#39;communityName&#39;, &#39;totalFloor&#39;])
    data = feature_count(data, [&#39;communityName&#39;, &#39;newWorkers&#39;])
    data = feature_count(data, [&#39;communityName&#39;, &#39;totalTradeMoney&#39;])
    new_train = data[data[&#39;data_type&#39;] == 0]
    new_test = data[data[&#39;data_type&#39;] == 1]
    new_train.drop(&#39;data_type&#39;, axis=1, inplace=True)
    new_test.drop([&#39;data_type&#39;], axis=1, inplace=True)
    return new_train, new_test

train, test = featureCount(train, test)
</code></pre>
<h3 id="groupby方法生成统计特征"><a href="#groupby方法生成统计特征" class="headerlink" title="groupby方法生成统计特征"></a>groupby方法生成统计特征</h3><pre><code class="lang-python">#groupby生成统计特征：mean,std等

def gourpby(train,test):
    train[&#39;data_type&#39;] = 0
    test[&#39;data_type&#39;] = 1
    data = pd.concat([train, test], axis=0, join=&#39;outer&#39;)
    columns = [&#39;rentType&#39;, &#39;houseFloor&#39;, &#39;houseToward&#39;, &#39;houseDecoration&#39;, &#39;communityName&#39;, &#39;region&#39;, &#39;plate&#39;]
    for feature in columns:
        data[feature] = LabelEncoder().fit_transform(data[feature])

    temp = data.groupby(&#39;communityName&#39;)[&#39;area&#39;].agg({&#39;com_area_mean&#39;: &#39;mean&#39;, &#39;com_area_std&#39;: &#39;std&#39;})
    temp.fillna(0, inplace=True)
    data = data.merge(temp, on=&#39;communityName&#39;, how=&#39;left&#39;)

    data[&#39;price_per_area&#39;] = data.tradeMeanPrice / data.area * 100
    temp = data.groupby(&#39;communityName&#39;)[&#39;price_per_area&#39;].agg(
        {&#39;comm_price_mean&#39;: &#39;mean&#39;, &#39;comm_price_std&#39;: &#39;std&#39;})
    temp.fillna(0, inplace=True)
    data = data.merge(temp, on=&#39;communityName&#39;, how=&#39;left&#39;)

    temp = data.groupby(&#39;plate&#39;)[&#39;price_per_area&#39;].agg(
        {&#39;plate_price_mean&#39;: &#39;mean&#39;, &#39;plate_price_std&#39;: &#39;std&#39;})
    temp.fillna(0, inplace=True)
    data = data.merge(temp, on=&#39;plate&#39;, how=&#39;left&#39;)
    data.drop(&#39;price_per_area&#39;, axis=1, inplace=True)

    temp = data.groupby(&#39;plate&#39;)[&#39;area&#39;].agg({&#39;plate_area_mean&#39;: &#39;mean&#39;, &#39;plate_area_std&#39;: &#39;std&#39;})
    temp.fillna(0, inplace=True)
    data = data.merge(temp, on=&#39;plate&#39;, how=&#39;left&#39;)

    temp = data.groupby([&#39;plate&#39;])[&#39;buildYear&#39;].agg({&#39;plate_year_mean&#39;: &#39;mean&#39;, &#39;plate_year_std&#39;: &#39;std&#39;})
    data = data.merge(temp, on=&#39;plate&#39;, how=&#39;left&#39;)
    data.plate_year_mean = data.plate_year_mean.astype(&#39;int&#39;)
    data[&#39;comm_plate_year_diff&#39;] = data.buildYear - data.plate_year_mean
    data.drop(&#39;plate_year_mean&#39;, axis=1, inplace=True)

    temp = data.groupby(&#39;plate&#39;)[&#39;trainsportNum&#39;].agg(&#39;sum&#39;).reset_index(name=&#39;plate_trainsportNum&#39;)
    data = data.merge(temp, on=&#39;plate&#39;, how=&#39;left&#39;)
    temp = data.groupby([&#39;communityName&#39;, &#39;plate&#39;])[&#39;trainsportNum&#39;].agg(&#39;sum&#39;).reset_index(name=&#39;com_trainsportNum&#39;)
    data = data.merge(temp, on=[&#39;communityName&#39;, &#39;plate&#39;], how=&#39;left&#39;)
    data[&#39;trainsportNum_ratio&#39;] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,
                                           data[&#39;com_trainsportNum&#39;], data[&#39;plate_trainsportNum&#39;]))
    data = data.drop([&#39;com_trainsportNum&#39;, &#39;plate_trainsportNum&#39;], axis=1)

    temp = data.groupby(&#39;plate&#39;)[&#39;all_SchoolNum&#39;].agg(&#39;sum&#39;).reset_index(name=&#39;plate_all_SchoolNum&#39;)
    data = data.merge(temp, on=&#39;plate&#39;, how=&#39;left&#39;)
    temp = data.groupby([&#39;communityName&#39;, &#39;plate&#39;])[&#39;all_SchoolNum&#39;].agg(&#39;sum&#39;).reset_index(name=&#39;com_all_SchoolNum&#39;)
    data = data.merge(temp, on=[&#39;communityName&#39;, &#39;plate&#39;], how=&#39;left&#39;)
    data = data.drop([&#39;com_all_SchoolNum&#39;, &#39;plate_all_SchoolNum&#39;], axis=1)

    temp = data.groupby([&#39;communityName&#39;, &#39;plate&#39;])[&#39;all_mall&#39;].agg(&#39;sum&#39;).reset_index(name=&#39;com_all_mall&#39;)
    data = data.merge(temp, on=[&#39;communityName&#39;, &#39;plate&#39;], how=&#39;left&#39;)

    temp = data.groupby(&#39;plate&#39;)[&#39;otherNum&#39;].agg(&#39;sum&#39;).reset_index(name=&#39;plate_otherNum&#39;)
    data = data.merge(temp, on=&#39;plate&#39;, how=&#39;left&#39;)
    temp = data.groupby([&#39;communityName&#39;, &#39;plate&#39;])[&#39;otherNum&#39;].agg(&#39;sum&#39;).reset_index(name=&#39;com_otherNum&#39;)
    data = data.merge(temp, on=[&#39;communityName&#39;, &#39;plate&#39;], how=&#39;left&#39;)
    data[&#39;other_ratio&#39;] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,
                                   data[&#39;com_otherNum&#39;], data[&#39;plate_otherNum&#39;]))
    data = data.drop([&#39;com_otherNum&#39;, &#39;plate_otherNum&#39;], axis=1)

    temp = data.groupby([&#39;month&#39;, &#39;communityName&#39;]).size().reset_index(name=&#39;communityName_saleNum&#39;)
    data = data.merge(temp, on=[&#39;month&#39;, &#39;communityName&#39;], how=&#39;left&#39;)
    temp = data.groupby([&#39;month&#39;, &#39;plate&#39;]).size().reset_index(name=&#39;plate_saleNum&#39;)
    data = data.merge(temp, on=[&#39;month&#39;, &#39;plate&#39;], how=&#39;left&#39;)

    data[&#39;sale_ratio&#39;] = round((data.communityName_saleNum + 1) / (data.plate_saleNum + 1), 3)
    data[&#39;sale_newworker_differ&#39;] = 3 * data.plate_saleNum - data.newWorkers
    data.drop([&#39;communityName_saleNum&#39;, &#39;plate_saleNum&#39;], axis=1, inplace=True)

    new_train = data[data[&#39;data_type&#39;] == 0]
    new_test = data[data[&#39;data_type&#39;] == 1]
    new_train.drop(&#39;data_type&#39;, axis=1, inplace=True)
    new_test.drop([&#39;data_type&#39;], axis=1, inplace=True)
    return new_train, new_test

train, test = gourpby(train, test)
</code></pre>
<h3 id="聚类方法"><a href="#聚类方法" class="headerlink" title="聚类方法"></a>聚类方法</h3><pre><code class="lang-python">#聚类
def cluster(train,test):
    from sklearn.mixture import GaussianMixture

    train[&#39;data_type&#39;] = 0
    test[&#39;data_type&#39;] = 1
    data = pd.concat([train, test], axis=0, join=&#39;outer&#39;)
    col = [&#39;totalFloor&#39;,
           &#39;houseDecoration&#39;, &#39;communityName&#39;, &#39;region&#39;, &#39;plate&#39;, &#39;buildYear&#39;,

           &#39;tradeMeanPrice&#39;, &#39;tradeSecNum&#39;, &#39;totalNewTradeMoney&#39;,
           &#39;totalNewTradeArea&#39;, &#39;tradeNewMeanPrice&#39;, &#39;tradeNewNum&#39;, &#39;remainNewNum&#39;,

           &#39;landTotalPrice&#39;, &#39;landMeanPrice&#39;, &#39;totalWorkers&#39;,
           &#39;newWorkers&#39;, &#39;residentPopulation&#39;, &#39;lookNum&#39;,
           &#39;trainsportNum&#39;,
           &#39;all_SchoolNum&#39;, &#39;all_hospitalNum&#39;, &#39;all_mall&#39;, &#39;otherNum&#39;]

    # EM
    gmm = GaussianMixture(n_components=3, covariance_type=&#39;full&#39;, random_state=0)
    data[&#39;cluster&#39;]= pd.DataFrame(gmm.fit_predict(data[col]))


    col1 = [&#39;totalFloor&#39;,&#39;houseDecoration&#39;, &#39;communityName&#39;, &#39;region&#39;, &#39;plate&#39;, &#39;buildYear&#39;]
    col2 = [&#39;tradeMeanPrice&#39;, &#39;tradeSecNum&#39;, &#39;totalNewTradeMoney&#39;,
            &#39;totalNewTradeArea&#39;, &#39;tradeNewMeanPrice&#39;, &#39;tradeNewNum&#39;, &#39;remainNewNum&#39;,
            &#39;landTotalPrice&#39;, &#39;landMeanPrice&#39;, &#39;totalWorkers&#39;,
            &#39;newWorkers&#39;, &#39;residentPopulation&#39;, &#39;lookNum&#39;,
            &#39;trainsportNum&#39;,
            &#39;all_SchoolNum&#39;, &#39;all_hospitalNum&#39;, &#39;all_mall&#39;, &#39;otherNum&#39;]
    for feature1 in col1:
        for feature2 in col2:

            temp = data.groupby([&#39;cluster&#39;,feature1])[feature2].agg(&#39;mean&#39;).reset_index(name=feature2+&#39;_&#39;+feature1+&#39;_cluster_mean&#39;)
            temp.fillna(0, inplace=True)

            data = data.merge(temp, on=[&#39;cluster&#39;, feature1], how=&#39;left&#39;)


    new_train = data[data[&#39;data_type&#39;] == 0]
    new_test = data[data[&#39;data_type&#39;] == 1]
    new_train.drop(&#39;data_type&#39;, axis=1, inplace=True)
    new_test.drop([&#39;data_type&#39;], axis=1, inplace=True)

    return new_train, new_test

train, test = cluster(train, test)
</code></pre>
<h3 id="log平滑"><a href="#log平滑" class="headerlink" title="log平滑"></a>log平滑</h3><pre><code class="lang-python"># 过大量级值取log平滑（针对线性模型有效）
big_num_cols = [&#39;totalTradeMoney&#39;,&#39;totalTradeArea&#39;,&#39;tradeMeanPrice&#39;,&#39;totalNewTradeMoney&#39;, &#39;totalNewTradeArea&#39;,
                &#39;tradeNewMeanPrice&#39;,&#39;remainNewNum&#39;, &#39;supplyNewNum&#39;, &#39;supplyLandArea&#39;,
                &#39;tradeLandArea&#39;,&#39;landTotalPrice&#39;,&#39;landMeanPrice&#39;,&#39;totalWorkers&#39;,&#39;newWorkers&#39;,
                &#39;residentPopulation&#39;,&#39;pv&#39;,&#39;uv&#39;]
for col in big_num_cols:
        train[col] = train[col].map(lambda x: np.log1p(x))
        test[col] = test[col].map(lambda x: np.log1p(x))
</code></pre>
<pre><code class="lang-python">#对比特征工程前后线性模型结果情况
test=test.fillna(0)
# Lasso回归
from sklearn.linear_model import Lasso
lasso=Lasso(alpha=0.1)
lasso.fit(train,target_train)
#预测测试集和训练集结果
y_pred_train=lasso.predict(train)
y_pred_test=lasso.predict(test)

#对比结果
from sklearn.metrics import r2_score
score_train=r2_score(y_pred_train,target_train)
print(&quot;训练集结果：&quot;,score_train)
score_test=r2_score(y_pred_test, target_test)
print(&quot;测试集结果：&quot;,score_test)
</code></pre>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><pre><code class="lang-python">import pandas as pd
import warnings
warnings.filterwarnings(&#39;ignore&#39;)
from sklearn.preprocessing import LabelEncoder
#读取数据
train = pd.read_csv(&#39;&#39;)
test = pd.read_csv(&#39;&#39;)

target_train = train.pop(&#39;tradeMoney&#39;)
target_test = test.pop(&#39;tradeMoney&#39;)
</code></pre>
<h3 id="相关系数法"><a href="#相关系数法" class="headerlink" title="相关系数法"></a>相关系数法</h3><pre><code class="lang-python">#相关系数法特征选择
from sklearn.feature_selection import SelectKBest

print(train.shape)

sk=SelectKBest(k=150)
new_train=sk.fit_transform(train,target_train)
print(new_train.shape)

# 获取对应列索引
select_columns=sk.get_support(indices = True)
# print(select_columns)

# 获取对应列名
# print(test.columns[select_columns])
select_columns_name=test.columns[select_columns]
new_test=test[select_columns_name]
print(new_test.shape)
# Lasso回归
from sklearn.linear_model import Lasso

lasso=Lasso(alpha=0.1)
lasso.fit(new_train,target_train)
#预测测试集和训练集结果
y_pred_train=lasso.predict(new_train)

y_pred_test=lasso.predict(new_test)

#对比结果
from sklearn.metrics import r2_score
score_train=r2_score(y_pred_train,target_train)
print(&quot;训练集结果：&quot;,score_train)
score_test=r2_score(y_pred_test, target_test)
print(&quot;测试集结果：&quot;,score_test)
</code></pre>
<h3 id="Wrapper"><a href="#Wrapper" class="headerlink" title="Wrapper"></a>Wrapper</h3><pre><code class="lang-python"># Wrapper

from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
rfe = RFE(lr, n_features_to_select=160)
rfe.fit(train,target_train)

RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
                               normalize=False),
    n_features_to_select=40, step=1, verbose=0)




select_columns = [f for f, s in zip(train.columns, rfe.support_) if s]
print(select_columns)
new_train = train[select_columns]
new_test = test[select_columns]

# Lasso回归
from sklearn.linear_model import Lasso

lasso=Lasso(alpha=0.1)
lasso.fit(new_train,target_train)
#预测测试集和训练集结果
y_pred_train=lasso.predict(new_train)

y_pred_test=lasso.predict(new_test)

#对比结果
from sklearn.metrics import r2_score
score_train=r2_score(y_pred_train,target_train)
print(&quot;训练集结果：&quot;,score_train)
score_test=r2_score(y_pred_test, target_test)
print(&quot;测试集结果：&quot;,score_test)
</code></pre>
<h3 id="Embedded"><a href="#Embedded" class="headerlink" title="Embedded"></a>Embedded</h3><h4 id="基于惩罚项的特征选择法"><a href="#基于惩罚项的特征选择法" class="headerlink" title="基于惩罚项的特征选择法"></a>基于惩罚项的特征选择法</h4><h4 id="Lasso-L1-和-Ridge-L2"><a href="#Lasso-L1-和-Ridge-L2" class="headerlink" title="Lasso(L1) 和 Ridge(L2)"></a>Lasso(L1) 和 Ridge(L2)</h4><pre><code class="lang-python"># Embedded
# 基于惩罚项的特征选择法
# Lasso(l1)和Ridge(l2)

from sklearn.linear_model import Ridge

ridge = Ridge(alpha=5)
ridge.fit(train,target_train)

Ridge(alpha=5, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,
      random_state=None, solver=&#39;auto&#39;, tol=0.001)

# 特征系数排序
coefSort = ridge.coef_.argsort()
print(coefSort)


# 特征系数
featureCoefSore=ridge.coef_[coefSort]
print(featureCoefSore)


select_columns = [f for f, s in zip(train.columns, featureCoefSore) if abs(s)&gt; 0.0000005 ] 
# 选择绝对值大于0.0000005的特征

new_train = train[select_columns]
new_test = test[select_columns]
# Lasso回归
from sklearn.linear_model import Lasso

lasso=Lasso(alpha=0.1)
lasso.fit(new_train,target_train)
#预测测试集和训练集结果
y_pred_train=lasso.predict(new_train)

y_pred_test=lasso.predict(new_test)

#对比结果
from sklearn.metrics import r2_score
score_train=r2_score(y_pred_train,target_train)
print(&quot;训练集结果：&quot;,score_train)
score_test=r2_score(y_pred_test, target_test)
print(&quot;测试集结果：&quot;,score_test)
</code></pre>
<h4 id="基于树模型的特征选择法"><a href="#基于树模型的特征选择法" class="headerlink" title="基于树模型的特征选择法"></a>基于树模型的特征选择法</h4><h4 id="随机森林-平均不纯度减少（mean-decrease-impurity）"><a href="#随机森林-平均不纯度减少（mean-decrease-impurity）" class="headerlink" title="随机森林 平均不纯度减少（mean decrease impurity）"></a>随机森林 平均不纯度减少（mean decrease impurity）</h4><pre><code class="lang-python"># Embedded
# 基于树模型的特征选择法
# 随机森林 平均不纯度减少（mean decrease impurity


from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
# 训练随机森林模型，并通过feature_importances_属性获取每个特征的重要性分数。rf = RandomForestRegressor()
rf.fit(train,target_train)
print(&quot;Features sorted by their score:&quot;)
print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), train.columns),
             reverse=True))

select_columns = [f for f, s in zip(train.columns, rf.feature_importances_) if abs(s)&gt; 0.00005 ] 
# 选择绝对值大于0.00005的特征

new_train = train[select_columns]
new_test = test[select_columns]

# Lasso回归
from sklearn.linear_model import Lasso

lasso=Lasso(alpha=0.1)
lasso.fit(new_train,target_train)
#预测测试集和训练集结果
y_pred_train=lasso.predict(new_train)

y_pred_test=lasso.predict(new_test)

#对比结果
from sklearn.metrics import r2_score
score_train=r2_score(y_pred_train,target_train)
print(&quot;训练集结果：&quot;,score_train)
score_test=r2_score(y_pred_test, target_test)
print(&quot;测试集结果：&quot;,score_test)
</code></pre>
<h2 id="四-模型选择"><a href="#四-模型选择" class="headerlink" title="(四) 模型选择"></a>(四) 模型选择</h2><h3 id="以-lightGBM-为例"><a href="#以-lightGBM-为例" class="headerlink" title="以 lightGBM 为例"></a>以 lightGBM 为例</h3><pre><code class="lang-py">from __future__ import print_function
import lightgbm as lgb
import sklearn
import numpy
import hyperopt
from hyperopt import hp, fmin, tpe, STATUS_OK, Trials
import colorama
import numpy as np

N_HYPEROPT_PROBES = 500
HYPEROPT_ALGO = tpe.suggest  #  tpe.suggest OR hyperopt.rand.suggest

# ----------------------------------------------------------

colorama.init()

# ---------------------------------------------------------------------

def get_lgb_params(space):
    lgb_params = dict()
    lgb_params[&#39;boosting_type&#39;] = space[&#39;boosting_type&#39;] if &#39;boosting_type&#39; in space else &#39;gbdt&#39;
    lgb_params[&#39;objective&#39;] = &#39;regression&#39;
    lgb_params[&#39;metric&#39;] = &#39;rmse&#39;
    lgb_params[&#39;learning_rate&#39;] = space[&#39;learning_rate&#39;]
    lgb_params[&#39;num_leaves&#39;] = int(space[&#39;num_leaves&#39;])
    lgb_params[&#39;min_data_in_leaf&#39;] = int(space[&#39;min_data_in_leaf&#39;])
    lgb_params[&#39;min_sum_hessian_in_leaf&#39;] = space[&#39;min_sum_hessian_in_leaf&#39;]
    lgb_params[&#39;max_depth&#39;] = -1
    lgb_params[&#39;lambda_l1&#39;] = space[&#39;lambda_l1&#39;] if &#39;lambda_l1&#39; in space else 0.0
    lgb_params[&#39;lambda_l2&#39;] = space[&#39;lambda_l2&#39;] if &#39;lambda_l2&#39; in space else 0.0
    lgb_params[&#39;max_bin&#39;] = int(space[&#39;max_bin&#39;]) if &#39;max_bin&#39; in space else 256
    lgb_params[&#39;feature_fraction&#39;] = space[&#39;feature_fraction&#39;]
    lgb_params[&#39;bagging_fraction&#39;] = space[&#39;bagging_fraction&#39;]
    lgb_params[&#39;bagging_freq&#39;] = int(space[&#39;bagging_freq&#39;]) if &#39;bagging_freq&#39; in space else 1
    lgb_params[&#39;nthread&#39;] = 4
    return lgb_params

# ---------------------------------------------------------------------

obj_call_count = 0
cur_best_score = 0 # 0 or np.inf
log_writer = open( &#39;../log/lgb-hyperopt-log.txt&#39;, &#39;w&#39; )


def objective(space):
    global obj_call_count, cur_best_score

    obj_call_count += 1

    print(&#39;\nLightGBM objective call #{} cur_best_score={:7.5f}&#39;.format(obj_call_count,cur_best_score) )

    lgb_params = get_lgb_params(space)

    sorted_params = sorted(space.items(), key=lambda z: z[0])
    params_str = str.join(&#39; &#39;, [&#39;{}={}&#39;.format(k, v) for k, v in sorted_params])
    print(&#39;Params: {}&#39;.format(params_str) )

    kf = KFold(n_splits=3, shuffle=True, random_state=0)
    out_of_fold = np.zeros(len(X_train))
    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):
        D_train = lgb.Dataset(X_train.iloc[train_idx], label=Y_train[train_idx])
        D_val = lgb.Dataset(X_train.iloc[val_idx], label=Y_train[val_idx])
        # Train
        num_round = 10000
        clf = lgb.train(lgb_params,
                           D_train,
                           num_boost_round=num_round,
                           # metrics=&#39;mlogloss&#39;,
                           valid_sets=D_val,
                           # valid_names=&#39;val&#39;,
                           # fobj=None,
                           # feval=None,
                           # init_model=None,
                           # feature_name=&#39;auto&#39;,
                           # categorical_feature=&#39;auto&#39;,
                           early_stopping_rounds=200,
                           # evals_result=None,
                           verbose_eval=False,
                           # learning_rates=None,
                           # keep_training_booster=False,
                           # callbacks=None
                           )
        # predict
        nb_trees = clf.best_iteration
        val_loss = clf.best_score[&#39;valid_0&#39;]
        print(&#39;nb_trees={} val_loss={}&#39;.format(nb_trees, val_loss))
        out_of_fold[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=nb_trees)
        score = r2_score(out_of_fold, Y_train)

    print(&#39;val_r2_score={}&#39;.format(score))

    log_writer.write(&#39;score={} Params:{} nb_trees={}\n&#39;.format(score, params_str, nb_trees ))
    log_writer.flush()

    if score&gt;cur_best_score:
        cur_best_score = score
        print(colorama.Fore.GREEN + &#39;NEW BEST SCORE={}&#39;.format(cur_best_score) + colorama.Fore.RESET)
    return {&#39;loss&#39;: -score, &#39;status&#39;: STATUS_OK}

# --------------------------------------------------------------------------------

space ={
        &#39;num_leaves&#39;: hp.quniform (&#39;num_leaves&#39;, 10, 100, 1),
        &#39;min_data_in_leaf&#39;:  hp.quniform (&#39;min_data_in_leaf&#39;, 10, 100, 1),
        &#39;feature_fraction&#39;: hp.uniform(&#39;feature_fraction&#39;, 0.75, 1.0),
        &#39;bagging_fraction&#39;: hp.uniform(&#39;bagging_fraction&#39;, 0.75, 1.0),
        &#39;learning_rate&#39;: hp.uniform(&#39;learning_rate&#39;, 0, 0.01),
#         &#39;learning_rate&#39;: hp.loguniform(&#39;learning_rate&#39;, -5.0, -2.3),
        &#39;min_sum_hessian_in_leaf&#39;: hp.loguniform(&#39;min_sum_hessian_in_leaf&#39;, 0, 2.3),
        &#39;max_bin&#39;: hp.quniform (&#39;max_bin&#39;, 88, 200, 1),
        &#39;bagging_freq&#39;: hp.quniform (&#39;bagging_freq&#39;, 1, 15, 1),
        &#39;lambda_l1&#39;: hp.uniform(&#39;lambda_l1&#39;, 0, 10 ),
        &#39;lambda_l2&#39;: hp.uniform(&#39;lambda_l2&#39;, 0, 10 ),
       }

trials = Trials()
best = hyperopt.fmin(fn=objective,
                     space=space,
                     algo=HYPEROPT_ALGO,
                     max_evals=N_HYPEROPT_PROBES,
                     trials=trials,
                     verbose=1)

print(&#39;-&#39;*50)
print(&#39;The best params:&#39;)
print( best )
print(&#39;\n\n&#39;)
</code></pre>
<h2 id="五-模型融合"><a href="#五-模型融合" class="headerlink" title="(五) 模型融合"></a>(五) 模型融合</h2><p>将特征放进模型中预测，并将预测结果作为新的特征加入原有特征中再经过模型预测结果（可以反复预测多次将结果加入最后的特征中）</p>
<pre><code class="lang-python">from sklearn.model_selection import KFold
    folds = KFold(n_splits=5, shuffle=True, random_state=2333)

    &quot;===================================第一轮========================================================&quot;
    y_pre_list = []
    r2_list = []
    train_feat = pd.Series()
    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):
        print(&quot;fold {}&quot;.format(fold_))
        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats)
        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)

        num_round = 10000
        clf = lgb.train(params, trn_data, num_round,valid_sets=[trn_data, val_data], verbose_eval=500,
                    early_stopping_rounds=200)
        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)
        r2 = r2_score(y_pre,label[val_idx])
        r2_list.append(r2)
        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))
        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)
        y_pre_list.append(y_pre_test)
    print(&#39;r2 score{:}&#39;.format(r2))
    print(&#39;r2:{:}&#39;.format(np.mean(r2_list)))

    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5
    feature[&#39;pre&#39;] = train_feat
    test[&#39;pre&#39;] = y_pred_final
    &quot;===================================第二轮========================================================&quot;
    y_pre_list = []
    r2_list = []
    train_feat = pd.Series()
    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):
        print(&quot;fold {}&quot;.format(fold_))
        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats)
        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)

        num_round = 10000
        clf = lgb.train(params, trn_data, num_round, feval=get_r2_metric,valid_sets=[trn_data, val_data], verbose_eval=500,
                    early_stopping_rounds=200)
        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)
        r2 = r2_score(y_pre,label[val_idx])
        r2_list.append(r2)
        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))
        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)
        y_pre_list.append(y_pre_test)
    print(&#39;r2 score{:}&#39;.format(r2))
    print(&#39;r2:{:}&#39;.format(np.mean(r2_list)))

    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5
    feature[&#39;pre_2&#39;] = train_feat
    test[&#39;pre_2&#39;] = y_pred_final
    &quot;=======================第三轮========================================================&quot;
    y_pre_list = []
    r2_list = []
    train_feat = pd.Series()
    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):
        print(&quot;fold {}&quot;.format(fold_))
        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats)
        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)

        num_round = 10000
        clf = lgb.train(params, trn_data, num_round, feval=get_r2_metric,valid_sets=[trn_data, val_data], verbose_eval=500,
                    early_stopping_rounds=200)
        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)
        r2 = r2_score(y_pre,label[val_idx])
        r2_list.append(r2)
        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))
        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)
        y_pre_list.append(y_pre_test)
    print(&#39;r2 score{:}&#39;.format(r2))
    print(&#39;r2:{:}&#39;.format(np.mean(r2_list)))

    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5

    return y_pred_final
</code></pre>
<p>pre1-pren分别是n组模型预测出来的结果，将其进行加权融合</p>
<pre><code class="lang-python">pre = (pre1 + pre2 + pre3 +...+pren )/n

pd.DataFrame(pre).to_csv(&quot;pre.csv&quot;,header=None,index=None)
</code></pre>
<h3 id="blending"><a href="#blending" class="headerlink" title="blending"></a>blending</h3><pre><code class="lang-python">def blend(train,test,target):
    &#39;&#39;&#39;5折&#39;&#39;&#39;
    # n_flods = 5
    # skf = list(StratifiedKFold(y, n_folds=n_flods))
    &#39;&#39;&#39;切分训练数据集为d1,d2两部分&#39;&#39;&#39;
    X_d1, X_d2, y_d1, y_d2 = train_test_split(train, target, test_size=0.5, random_state=914)

    train_ = np.zeros((X_d2.shape[0],len(clfs*3)))
    test_ = np.zeros((test.shape[0],len(clfs*3)))

    for j,clf in enumerate(clfs):
        &#39;&#39;&#39;依次训练各个单模型&#39;&#39;&#39;
        # print(j, clf)
        &#39;&#39;&#39;使用第1个部分作为预测，第2部分来训练模型，获得其预测的输出作为第2部分的新特征。&#39;&#39;&#39;
        # X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]
        X_d1fillna=X_d1.fillna(0)
        X_d2fillna = X_d2.fillna(0)

        X_predictfillna= test.fillna(0)

        clf.fit(X_d1fillna,y_d1)
        y_submission = clf.predict(X_d2fillna)
        y_test_submission = clf.predict(X_predictfillna)

        train_[:,j*3] = y_submission*y_submission
        &#39;&#39;&#39;对于测试集，直接用这k个模型的预测值作为新的特征。&#39;&#39;&#39;
        test_[:, j*3] = y_test_submission*y_test_submission

        train_[:, j+1] =(y_submission - y_submission.min()) /(y_submission.max() - y_submission.min())
        &#39;&#39;&#39;对于测试集，直接用这k个模型的预测值作为新的特征。&#39;&#39;&#39;
        y_test_submission = (y_test_submission - y_test_submission.min()) / \
                            (y_test_submission.max() - y_test_submission.min())
        test_[:, j+1] = y_test_submission

        train_[:, j+2] = np.log(y_submission)
        &#39;&#39;&#39;对于测试集，直接用这k个模型的预测值作为新的特征。&#39;&#39;&#39;
        y_test_submission =np.log(y_test_submission)
        test_[:, j+2] = y_test_submission



        # print(&quot;val auc Score: %f&quot; % r2_score(y_predict, dataset_d2[:, j]))
        print(&#39;已完成第&#39;,j)

    train_.to_csv(&#39;./input/train_blending.csv&#39;, index=False)
    test_.to_csv(&#39;./input/test_blending.csv&#39;, index=False)
</code></pre>
<h3 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h3><pre><code class="lang-python">#!pip install mlxtend

import warnings
warnings.filterwarnings(&#39;ignore&#39;)
import itertools
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from sklearn import datasets
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB 
from sklearn.ensemble import RandomForestClassifier
from mlxtend.classifier import StackingClassifier
from sklearn.model_selection import cross_val_score, train_test_split
from mlxtend.plotting import plot_learning_curves
from mlxtend.plotting import plot_decision_regions
</code></pre>
<pre><code class="lang-python"># 以python自带的鸢尾花数据集为例
iris = datasets.load_iris()
X, y = iris.data[:, 1:3], iris.target

clf1 = KNeighborsClassifier(n_neighbors=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()
lr = LogisticRegression()
sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], 
                          meta_classifier=lr)

label = [&#39;KNN&#39;, &#39;Random Forest&#39;, &#39;Naive Bayes&#39;, &#39;Stacking Classifier&#39;]
clf_list = [clf1, clf2, clf3, sclf]

fig = plt.figure(figsize=(10,8))
gs = gridspec.GridSpec(2, 2)
grid = itertools.product([0,1],repeat=2)

clf_cv_mean = []
clf_cv_std = []
for clf, label, grd in zip(clf_list, label, grid):

    scores = cross_val_score(clf, X, y, cv=3, scoring=&#39;accuracy&#39;)
    print(&quot;Accuracy: %.2f (+/- %.2f) [%s]&quot; %(scores.mean(), scores.std(), label))
    clf_cv_mean.append(scores.mean())
    clf_cv_std.append(scores.std())

    clf.fit(X, y)
    ax = plt.subplot(gs[grd[0], grd[1]])
    fig = plot_decision_regions(X=X, y=y, clf=clf)
    plt.title(label)

plt.show()
</code></pre>
<pre><code>Accuracy: 0.91 (+/- 0.01) [KNN]
Accuracy: 0.93 (+/- 0.05) [Random Forest]
Accuracy: 0.92 (+/- 0.03) [Naive Bayes]
Accuracy: 0.95 (+/- 0.03) [Stacking Classifier]
</code></pre><p><img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://i.loli.net/2020/02/26/aGs18DEHCYZFnoP.png" alt=""></p>
<h2 id="六-总结"><a href="#六-总结" class="headerlink" title="(六) 总结"></a>(六) 总结</h2><p><a href="https://blog.csdn.net/qq_39756719/article/details/95634744" target="_blank" rel="noopener">答辩 ppt</a></p>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://hopenx.github.io" rel="external nofollow noreferrer">HopenX</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://hopenx.github.io/2020/02/26/housing-project/">https://hopenx.github.io/2020/02/26/housing-project/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://hopenx.github.io" target="_blank">HopenX</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">机器学习</span>
                                </a>
                            
                                <a href="/tags/project/">
                                    <span class="chip bg-color">project</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/2020/02/26/housing-project/">
                    <div class="card-image">
                        
                        
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/featureimages/17.jpg" class="responsive-img" alt="竞赛-房租预测">
                        
                        <span class="card-title">竞赛-房租预测</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            比赛要求参赛选手根据给定的数据集，建立模型，预测房屋租金, 数据集中的数据类别包括租赁房源、小区、二手房、配套、新房、土地、人口、客户、真实租金等
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-02-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">机器学习</span>
                    </a>
                    
                    <a href="/tags/project/">
                        <span class="chip bg-color">project</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/02/20/dl-notes11-modern-cnn/">
                    <div class="card-image">
                        
                        
                        <img src="https://i.loli.net/2020/02/09/2OERK3tFJve4YDH.gif" data-original="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/medias/featureimages/2.jpg" class="responsive-img" alt="动手深度学习(十一):现代 CNN 模型">
                        
                        <span class="card-title">动手深度学习(十一):现代 CNN 模型</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            简要介绍 CV 领域近 10 年来诞生的一系列模型, AlexNet, VGG, NiN, GoogLeNet, 同时深度理解卷积工作原理
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-02-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/CV/">
                        <span class="chip bg-color">CV</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>


    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://hopenx.github.io" target="_blank">HopenX</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">64.2k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "1";
                    var startDate = "2";
                    var startHour = "0";
                    var startMinute = "";
                    var startSecond = "";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 ";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/hopenx" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>









    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1152214965" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1152214965" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>

<script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    
    
    
    <script src="https://cdn.jsdelivr.net/gh/hopenx/hopenx.github.io@master/libs/instantpage/instantpage.js" type="module"></script>
    

<script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>
